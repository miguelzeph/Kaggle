{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_csv('./train.csv')\n",
    "y_env = dados[['Survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = dados.drop(['PassengerId','Name','Ticket','Cabin','Fare','Embarked'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sex(x):\n",
    "    if x == 'male':\n",
    "        return 0\n",
    "    if x == 'female':\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados['Sex'] = dados['Sex'].apply(sex)\n",
    "\n",
    "dados = pd.get_dummies(dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dados = dados.dropna().reset_index().drop('index',axis=1)\n",
    "# tudo que for NaN vira valor MÃ©dio\n",
    "\n",
    "def media_age(x):\n",
    "    if np.isnan(x) == True :\n",
    "        return int(dados['Age'].mean()+10)\n",
    "        \n",
    "    else:\n",
    "        return x\n",
    "\n",
    "    \n",
    "dados['Age'] = dados['Age'].apply(media_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age  SibSp  Parch\n",
       "0         0       3    0  22.0      1      0\n",
       "1         1       1    1  38.0      1      0\n",
       "2         1       3    1  26.0      0      0\n",
       "3         1       1    1  35.0      1      0\n",
       "4         0       3    0  35.0      0      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dados.drop('Survived',axis=1)\n",
    "y = dados[['Survived']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((891, 5), (891, 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ny = scaler.fit_transform(y)\\ndf = pd.DataFrame()\\ndf['Survived'] = y[:,0]\\ny = df\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import  StandardScaler, MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "#scaler = StandardScaler()\n",
    "\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "\"\"\"\n",
    "y = scaler.fit_transform(y)\n",
    "df = pd.DataFrame()\n",
    "df['Survived'] = y[:,0]\n",
    "y = df\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size = 0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_model(n):\n",
    "  model = tf.keras.models.Sequential()\n",
    "\n",
    "\n",
    "\n",
    "  model.add(tf.keras.layers.Dense(\n",
    "      units = n*4,\n",
    "      activation = 'relu',\n",
    "      input_shape = (X_train.shape[1],)\n",
    "  ))\n",
    "\n",
    "  model.add(tf.keras.layers.Dense(\n",
    "      units = n*2,\n",
    "      activation = 'relu',\n",
    "      \n",
    "  ))\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "  model.add(tf.keras.layers.Dense(\n",
    "      units = 1,\n",
    "      activation = 'sigmoid',\n",
    "  ))\n",
    "\n",
    "  #model.summary()\n",
    "\n",
    "  model.compile(loss = 'binary_crossentropy', optimizer = 'Adam', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "  return model\n",
    "\n",
    "def treinar(model, epochs):\n",
    "\n",
    "  history = model.fit(\n",
    "      X_train,\n",
    "      y_train,\n",
    "      validation_split=0.1,\n",
    "      epochs = epochs,\n",
    "      shuffle = True,\n",
    "      )\n",
    "  return history\n",
    "\n",
    "  #history.history.keys()\n",
    "\n",
    "def cond(x):\n",
    "    if x > 0.5:\n",
    "      return 1\n",
    "    else:\n",
    "      return 0\n",
    "\n",
    "def predict(X,y,model):\n",
    "\n",
    "  pred_train = model.predict(X)\n",
    "  pred_train.shape\n",
    "\n",
    "  pred_df = pd.DataFrame()\n",
    "  pred_df['pred'] = pred_train[:,0]\n",
    "\n",
    "  pred_df['pred'] = pred_df['pred'].apply(cond)\n",
    "\n",
    "  y_train_pred = y.join(pred_df)\n",
    "\n",
    "  k = 0\n",
    "  total = len(y_train_pred['pred'])\n",
    "\n",
    "  for x,y in zip(y_train_pred['pred'],y_train_pred['Survived']):\n",
    "      if x == y:\n",
    "          k = k+1\n",
    "  p = k/total\n",
    "  p_ = np.around(p*100,2)\n",
    "  print(f\"Porcentagem de Acerto {p_}%\")\n",
    "  return p_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 793 samples, validate on 89 samples\n",
      "Epoch 1/40\n",
      "793/793 [==============================] - 1s 638us/sample - loss: 0.7121 - accuracy: 0.3770 - val_loss: 0.7048 - val_accuracy: 0.3933\n",
      "Epoch 2/40\n",
      "793/793 [==============================] - 0s 80us/sample - loss: 0.6868 - accuracy: 0.4086 - val_loss: 0.6896 - val_accuracy: 0.5393\n",
      "Epoch 3/40\n",
      "793/793 [==============================] - 0s 101us/sample - loss: 0.6652 - accuracy: 0.6003 - val_loss: 0.6785 - val_accuracy: 0.6629\n",
      "Epoch 4/40\n",
      "793/793 [==============================] - 0s 101us/sample - loss: 0.6484 - accuracy: 0.7743 - val_loss: 0.6710 - val_accuracy: 0.6966\n",
      "Epoch 5/40\n",
      "793/793 [==============================] - 0s 77us/sample - loss: 0.6359 - accuracy: 0.7806 - val_loss: 0.6675 - val_accuracy: 0.7079\n",
      "Epoch 6/40\n",
      "793/793 [==============================] - 0s 72us/sample - loss: 0.6259 - accuracy: 0.7881 - val_loss: 0.6641 - val_accuracy: 0.7079\n",
      "Epoch 7/40\n",
      "793/793 [==============================] - 0s 72us/sample - loss: 0.6175 - accuracy: 0.7919 - val_loss: 0.6603 - val_accuracy: 0.7079\n",
      "Epoch 8/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.6099 - accuracy: 0.7919 - val_loss: 0.6565 - val_accuracy: 0.7079\n",
      "Epoch 9/40\n",
      "793/793 [==============================] - 0s 108us/sample - loss: 0.6036 - accuracy: 0.7945 - val_loss: 0.6540 - val_accuracy: 0.7079\n",
      "Epoch 10/40\n",
      "793/793 [==============================] - 0s 88us/sample - loss: 0.5962 - accuracy: 0.7945 - val_loss: 0.6486 - val_accuracy: 0.6966\n",
      "Epoch 11/40\n",
      "793/793 [==============================] - 0s 76us/sample - loss: 0.5902 - accuracy: 0.7945 - val_loss: 0.6455 - val_accuracy: 0.6966\n",
      "Epoch 12/40\n",
      "793/793 [==============================] - 0s 78us/sample - loss: 0.5841 - accuracy: 0.7945 - val_loss: 0.6411 - val_accuracy: 0.6966\n",
      "Epoch 13/40\n",
      "793/793 [==============================] - 0s 97us/sample - loss: 0.5783 - accuracy: 0.7945 - val_loss: 0.6373 - val_accuracy: 0.6966\n",
      "Epoch 14/40\n",
      "793/793 [==============================] - 0s 81us/sample - loss: 0.5728 - accuracy: 0.7945 - val_loss: 0.6339 - val_accuracy: 0.6966\n",
      "Epoch 15/40\n",
      "793/793 [==============================] - 0s 75us/sample - loss: 0.5675 - accuracy: 0.7945 - val_loss: 0.6301 - val_accuracy: 0.6966\n",
      "Epoch 16/40\n",
      "793/793 [==============================] - 0s 74us/sample - loss: 0.5623 - accuracy: 0.7945 - val_loss: 0.6260 - val_accuracy: 0.6966\n",
      "Epoch 17/40\n",
      "793/793 [==============================] - 0s 88us/sample - loss: 0.5572 - accuracy: 0.7945 - val_loss: 0.6220 - val_accuracy: 0.6966\n",
      "Epoch 18/40\n",
      "793/793 [==============================] - 0s 94us/sample - loss: 0.5523 - accuracy: 0.7945 - val_loss: 0.6180 - val_accuracy: 0.6966\n",
      "Epoch 19/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.5479 - accuracy: 0.7945 - val_loss: 0.6133 - val_accuracy: 0.6966\n",
      "Epoch 20/40\n",
      "793/793 [==============================] - 0s 101us/sample - loss: 0.5429 - accuracy: 0.7945 - val_loss: 0.6103 - val_accuracy: 0.6966\n",
      "Epoch 21/40\n",
      "793/793 [==============================] - 0s 98us/sample - loss: 0.5383 - accuracy: 0.7945 - val_loss: 0.6059 - val_accuracy: 0.6966\n",
      "Epoch 22/40\n",
      "793/793 [==============================] - 0s 94us/sample - loss: 0.5343 - accuracy: 0.7945 - val_loss: 0.6017 - val_accuracy: 0.6966\n",
      "Epoch 23/40\n",
      "793/793 [==============================] - 0s 96us/sample - loss: 0.5299 - accuracy: 0.7945 - val_loss: 0.5990 - val_accuracy: 0.6966\n",
      "Epoch 24/40\n",
      "793/793 [==============================] - 0s 102us/sample - loss: 0.5259 - accuracy: 0.7945 - val_loss: 0.5953 - val_accuracy: 0.6966\n",
      "Epoch 25/40\n",
      "793/793 [==============================] - 0s 81us/sample - loss: 0.5220 - accuracy: 0.7945 - val_loss: 0.5928 - val_accuracy: 0.6966\n",
      "Epoch 26/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.5185 - accuracy: 0.7945 - val_loss: 0.5905 - val_accuracy: 0.6966\n",
      "Epoch 27/40\n",
      "793/793 [==============================] - 0s 94us/sample - loss: 0.5151 - accuracy: 0.7945 - val_loss: 0.5866 - val_accuracy: 0.6966\n",
      "Epoch 28/40\n",
      "793/793 [==============================] - 0s 98us/sample - loss: 0.5120 - accuracy: 0.7982 - val_loss: 0.5840 - val_accuracy: 0.6966\n",
      "Epoch 29/40\n",
      "793/793 [==============================] - 0s 94us/sample - loss: 0.5094 - accuracy: 0.7982 - val_loss: 0.5823 - val_accuracy: 0.6966\n",
      "Epoch 30/40\n",
      "793/793 [==============================] - 0s 101us/sample - loss: 0.5059 - accuracy: 0.7982 - val_loss: 0.5798 - val_accuracy: 0.6966\n",
      "Epoch 31/40\n",
      "793/793 [==============================] - 0s 73us/sample - loss: 0.5027 - accuracy: 0.7995 - val_loss: 0.5766 - val_accuracy: 0.7191\n",
      "Epoch 32/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.5003 - accuracy: 0.8008 - val_loss: 0.5742 - val_accuracy: 0.7416\n",
      "Epoch 33/40\n",
      "793/793 [==============================] - 0s 76us/sample - loss: 0.4979 - accuracy: 0.8008 - val_loss: 0.5734 - val_accuracy: 0.7416\n",
      "Epoch 34/40\n",
      "793/793 [==============================] - 0s 72us/sample - loss: 0.4949 - accuracy: 0.8020 - val_loss: 0.5706 - val_accuracy: 0.7416\n",
      "Epoch 35/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.4925 - accuracy: 0.8071 - val_loss: 0.5693 - val_accuracy: 0.7416\n",
      "Epoch 36/40\n",
      "793/793 [==============================] - 0s 104us/sample - loss: 0.4901 - accuracy: 0.8071 - val_loss: 0.5675 - val_accuracy: 0.7416\n",
      "Epoch 37/40\n",
      "793/793 [==============================] - 0s 74us/sample - loss: 0.4881 - accuracy: 0.8071 - val_loss: 0.5661 - val_accuracy: 0.7416\n",
      "Epoch 38/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4859 - accuracy: 0.8071 - val_loss: 0.5650 - val_accuracy: 0.7416\n",
      "Epoch 39/40\n",
      "793/793 [==============================] - 0s 73us/sample - loss: 0.4841 - accuracy: 0.8071 - val_loss: 0.5631 - val_accuracy: 0.7416\n",
      "Epoch 40/40\n",
      "793/793 [==============================] - 0s 74us/sample - loss: 0.4821 - accuracy: 0.8096 - val_loss: 0.5621 - val_accuracy: 0.7640\n",
      "Porcentagem de Acerto 53.63%\n",
      "Porcentagem de Acerto 0.0%\n",
      "Train on 793 samples, validate on 89 samples\n",
      "Epoch 1/40\n",
      "793/793 [==============================] - 0s 605us/sample - loss: 0.7009 - accuracy: 0.6166 - val_loss: 0.6767 - val_accuracy: 0.6180\n",
      "Epoch 2/40\n",
      "793/793 [==============================] - 0s 75us/sample - loss: 0.6751 - accuracy: 0.6166 - val_loss: 0.6605 - val_accuracy: 0.6180\n",
      "Epoch 3/40\n",
      "793/793 [==============================] - 0s 80us/sample - loss: 0.6459 - accuracy: 0.6166 - val_loss: 0.6406 - val_accuracy: 0.6067\n",
      "Epoch 4/40\n",
      "793/793 [==============================] - 0s 71us/sample - loss: 0.6116 - accuracy: 0.6646 - val_loss: 0.6176 - val_accuracy: 0.6629\n",
      "Epoch 5/40\n",
      "793/793 [==============================] - 0s 76us/sample - loss: 0.5718 - accuracy: 0.7755 - val_loss: 0.5941 - val_accuracy: 0.7079\n",
      "Epoch 6/40\n",
      "793/793 [==============================] - 0s 85us/sample - loss: 0.5335 - accuracy: 0.7982 - val_loss: 0.5784 - val_accuracy: 0.6854\n",
      "Epoch 7/40\n",
      "793/793 [==============================] - 0s 82us/sample - loss: 0.5043 - accuracy: 0.7945 - val_loss: 0.5684 - val_accuracy: 0.6966\n",
      "Epoch 8/40\n",
      "793/793 [==============================] - 0s 77us/sample - loss: 0.4814 - accuracy: 0.7995 - val_loss: 0.5614 - val_accuracy: 0.6966\n",
      "Epoch 9/40\n",
      "793/793 [==============================] - 0s 74us/sample - loss: 0.4666 - accuracy: 0.7957 - val_loss: 0.5575 - val_accuracy: 0.6966\n",
      "Epoch 10/40\n",
      "793/793 [==============================] - 0s 86us/sample - loss: 0.4576 - accuracy: 0.7957 - val_loss: 0.5567 - val_accuracy: 0.6966\n",
      "Epoch 11/40\n",
      "793/793 [==============================] - 0s 76us/sample - loss: 0.4508 - accuracy: 0.7970 - val_loss: 0.5541 - val_accuracy: 0.7079\n",
      "Epoch 12/40\n",
      "793/793 [==============================] - 0s 80us/sample - loss: 0.4465 - accuracy: 0.8008 - val_loss: 0.5494 - val_accuracy: 0.7079\n",
      "Epoch 13/40\n",
      "793/793 [==============================] - 0s 83us/sample - loss: 0.4431 - accuracy: 0.8020 - val_loss: 0.5478 - val_accuracy: 0.7079\n",
      "Epoch 14/40\n",
      "793/793 [==============================] - 0s 74us/sample - loss: 0.4404 - accuracy: 0.8008 - val_loss: 0.5443 - val_accuracy: 0.7079\n",
      "Epoch 15/40\n",
      "793/793 [==============================] - 0s 69us/sample - loss: 0.4370 - accuracy: 0.8008 - val_loss: 0.5418 - val_accuracy: 0.7303\n",
      "Epoch 16/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "793/793 [==============================] - 0s 79us/sample - loss: 0.4351 - accuracy: 0.8008 - val_loss: 0.5398 - val_accuracy: 0.7416\n",
      "Epoch 17/40\n",
      "793/793 [==============================] - 0s 75us/sample - loss: 0.4325 - accuracy: 0.8033 - val_loss: 0.5372 - val_accuracy: 0.7303\n",
      "Epoch 18/40\n",
      "793/793 [==============================] - 0s 82us/sample - loss: 0.4305 - accuracy: 0.7995 - val_loss: 0.5365 - val_accuracy: 0.7303\n",
      "Epoch 19/40\n",
      "793/793 [==============================] - 0s 76us/sample - loss: 0.4275 - accuracy: 0.7970 - val_loss: 0.5346 - val_accuracy: 0.7640\n",
      "Epoch 20/40\n",
      "793/793 [==============================] - 0s 78us/sample - loss: 0.4248 - accuracy: 0.8008 - val_loss: 0.5327 - val_accuracy: 0.7640\n",
      "Epoch 21/40\n",
      "793/793 [==============================] - 0s 70us/sample - loss: 0.4230 - accuracy: 0.7957 - val_loss: 0.5326 - val_accuracy: 0.7753\n",
      "Epoch 22/40\n",
      "793/793 [==============================] - 0s 81us/sample - loss: 0.4213 - accuracy: 0.8020 - val_loss: 0.5322 - val_accuracy: 0.7865\n",
      "Epoch 23/40\n",
      "793/793 [==============================] - 0s 77us/sample - loss: 0.4213 - accuracy: 0.8033 - val_loss: 0.5291 - val_accuracy: 0.7640\n",
      "Epoch 24/40\n",
      "793/793 [==============================] - 0s 85us/sample - loss: 0.4185 - accuracy: 0.8045 - val_loss: 0.5292 - val_accuracy: 0.7640\n",
      "Epoch 25/40\n",
      "793/793 [==============================] - 0s 87us/sample - loss: 0.4180 - accuracy: 0.8071 - val_loss: 0.5330 - val_accuracy: 0.7865\n",
      "Epoch 26/40\n",
      "793/793 [==============================] - 0s 74us/sample - loss: 0.4166 - accuracy: 0.8071 - val_loss: 0.5305 - val_accuracy: 0.7865\n",
      "Epoch 27/40\n",
      "793/793 [==============================] - 0s 73us/sample - loss: 0.4155 - accuracy: 0.8058 - val_loss: 0.5302 - val_accuracy: 0.7640\n",
      "Epoch 28/40\n",
      "793/793 [==============================] - 0s 96us/sample - loss: 0.4153 - accuracy: 0.8083 - val_loss: 0.5302 - val_accuracy: 0.7640\n",
      "Epoch 29/40\n",
      "793/793 [==============================] - 0s 89us/sample - loss: 0.4144 - accuracy: 0.8159 - val_loss: 0.5317 - val_accuracy: 0.7640\n",
      "Epoch 30/40\n",
      "793/793 [==============================] - 0s 80us/sample - loss: 0.4145 - accuracy: 0.8071 - val_loss: 0.5316 - val_accuracy: 0.7753\n",
      "Epoch 31/40\n",
      "793/793 [==============================] - 0s 89us/sample - loss: 0.4128 - accuracy: 0.8134 - val_loss: 0.5343 - val_accuracy: 0.7640\n",
      "Epoch 32/40\n",
      "793/793 [==============================] - 0s 78us/sample - loss: 0.4127 - accuracy: 0.8083 - val_loss: 0.5305 - val_accuracy: 0.7753\n",
      "Epoch 33/40\n",
      "793/793 [==============================] - 0s 86us/sample - loss: 0.4115 - accuracy: 0.8134 - val_loss: 0.5332 - val_accuracy: 0.7865\n",
      "Epoch 34/40\n",
      "793/793 [==============================] - 0s 85us/sample - loss: 0.4112 - accuracy: 0.8172 - val_loss: 0.5336 - val_accuracy: 0.7865\n",
      "Epoch 35/40\n",
      "793/793 [==============================] - 0s 78us/sample - loss: 0.4101 - accuracy: 0.8083 - val_loss: 0.5313 - val_accuracy: 0.7865\n",
      "Epoch 36/40\n",
      "793/793 [==============================] - 0s 89us/sample - loss: 0.4097 - accuracy: 0.8134 - val_loss: 0.5322 - val_accuracy: 0.7640\n",
      "Epoch 37/40\n",
      "793/793 [==============================] - 0s 75us/sample - loss: 0.4092 - accuracy: 0.8134 - val_loss: 0.5310 - val_accuracy: 0.7640\n",
      "Epoch 38/40\n",
      "793/793 [==============================] - 0s 81us/sample - loss: 0.4096 - accuracy: 0.8108 - val_loss: 0.5308 - val_accuracy: 0.7753\n",
      "Epoch 39/40\n",
      "793/793 [==============================] - 0s 84us/sample - loss: 0.4085 - accuracy: 0.8096 - val_loss: 0.5323 - val_accuracy: 0.7753\n",
      "Epoch 40/40\n",
      "793/793 [==============================] - 0s 80us/sample - loss: 0.4074 - accuracy: 0.8121 - val_loss: 0.5324 - val_accuracy: 0.7865\n",
      "Porcentagem de Acerto 52.72%\n",
      "Porcentagem de Acerto 0.0%\n",
      "Train on 793 samples, validate on 89 samples\n",
      "Epoch 1/40\n",
      "793/793 [==============================] - 0s 607us/sample - loss: 0.6445 - accuracy: 0.6166 - val_loss: 0.6297 - val_accuracy: 0.6180\n",
      "Epoch 2/40\n",
      "793/793 [==============================] - 0s 83us/sample - loss: 0.5995 - accuracy: 0.6166 - val_loss: 0.6015 - val_accuracy: 0.6180\n",
      "Epoch 3/40\n",
      "793/793 [==============================] - 0s 86us/sample - loss: 0.5682 - accuracy: 0.7024 - val_loss: 0.5828 - val_accuracy: 0.7079\n",
      "Epoch 4/40\n",
      "793/793 [==============================] - 0s 76us/sample - loss: 0.5446 - accuracy: 0.7793 - val_loss: 0.5709 - val_accuracy: 0.7079\n",
      "Epoch 5/40\n",
      "793/793 [==============================] - 0s 85us/sample - loss: 0.5264 - accuracy: 0.7932 - val_loss: 0.5602 - val_accuracy: 0.7079\n",
      "Epoch 6/40\n",
      "793/793 [==============================] - 0s 88us/sample - loss: 0.5087 - accuracy: 0.7945 - val_loss: 0.5533 - val_accuracy: 0.7191\n",
      "Epoch 7/40\n",
      "793/793 [==============================] - 0s 81us/sample - loss: 0.4947 - accuracy: 0.7982 - val_loss: 0.5491 - val_accuracy: 0.7416\n",
      "Epoch 8/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.4820 - accuracy: 0.8020 - val_loss: 0.5423 - val_accuracy: 0.7416\n",
      "Epoch 9/40\n",
      "793/793 [==============================] - 0s 78us/sample - loss: 0.4698 - accuracy: 0.8058 - val_loss: 0.5398 - val_accuracy: 0.7416\n",
      "Epoch 10/40\n",
      "793/793 [==============================] - 0s 77us/sample - loss: 0.4604 - accuracy: 0.8033 - val_loss: 0.5379 - val_accuracy: 0.7079\n",
      "Epoch 11/40\n",
      "793/793 [==============================] - 0s 84us/sample - loss: 0.4543 - accuracy: 0.8020 - val_loss: 0.5352 - val_accuracy: 0.7416\n",
      "Epoch 12/40\n",
      "793/793 [==============================] - 0s 75us/sample - loss: 0.4498 - accuracy: 0.8045 - val_loss: 0.5348 - val_accuracy: 0.7416\n",
      "Epoch 13/40\n",
      "793/793 [==============================] - 0s 72us/sample - loss: 0.4460 - accuracy: 0.8045 - val_loss: 0.5337 - val_accuracy: 0.7416\n",
      "Epoch 14/40\n",
      "793/793 [==============================] - 0s 77us/sample - loss: 0.4446 - accuracy: 0.7995 - val_loss: 0.5323 - val_accuracy: 0.7416\n",
      "Epoch 15/40\n",
      "793/793 [==============================] - 0s 70us/sample - loss: 0.4402 - accuracy: 0.8020 - val_loss: 0.5330 - val_accuracy: 0.7416\n",
      "Epoch 16/40\n",
      "793/793 [==============================] - 0s 75us/sample - loss: 0.4381 - accuracy: 0.8045 - val_loss: 0.5331 - val_accuracy: 0.7416\n",
      "Epoch 17/40\n",
      "793/793 [==============================] - 0s 81us/sample - loss: 0.4355 - accuracy: 0.8020 - val_loss: 0.5298 - val_accuracy: 0.7416\n",
      "Epoch 18/40\n",
      "793/793 [==============================] - 0s 87us/sample - loss: 0.4339 - accuracy: 0.8045 - val_loss: 0.5302 - val_accuracy: 0.7640\n",
      "Epoch 19/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4335 - accuracy: 0.8071 - val_loss: 0.5281 - val_accuracy: 0.7416\n",
      "Epoch 20/40\n",
      "793/793 [==============================] - 0s 75us/sample - loss: 0.4310 - accuracy: 0.8033 - val_loss: 0.5316 - val_accuracy: 0.7640\n",
      "Epoch 21/40\n",
      "793/793 [==============================] - 0s 80us/sample - loss: 0.4323 - accuracy: 0.8033 - val_loss: 0.5302 - val_accuracy: 0.7640\n",
      "Epoch 22/40\n",
      "793/793 [==============================] - 0s 94us/sample - loss: 0.4300 - accuracy: 0.8096 - val_loss: 0.5293 - val_accuracy: 0.7640\n",
      "Epoch 23/40\n",
      "793/793 [==============================] - 0s 74us/sample - loss: 0.4272 - accuracy: 0.8083 - val_loss: 0.5286 - val_accuracy: 0.7640\n",
      "Epoch 24/40\n",
      "793/793 [==============================] - 0s 77us/sample - loss: 0.4278 - accuracy: 0.8058 - val_loss: 0.5285 - val_accuracy: 0.7640\n",
      "Epoch 25/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.4255 - accuracy: 0.8083 - val_loss: 0.5284 - val_accuracy: 0.7640\n",
      "Epoch 26/40\n",
      "793/793 [==============================] - 0s 75us/sample - loss: 0.4251 - accuracy: 0.8121 - val_loss: 0.5289 - val_accuracy: 0.7640\n",
      "Epoch 27/40\n",
      "793/793 [==============================] - 0s 86us/sample - loss: 0.4240 - accuracy: 0.8083 - val_loss: 0.5278 - val_accuracy: 0.7640\n",
      "Epoch 28/40\n",
      "793/793 [==============================] - 0s 78us/sample - loss: 0.4237 - accuracy: 0.8108 - val_loss: 0.5301 - val_accuracy: 0.7640\n",
      "Epoch 29/40\n",
      "793/793 [==============================] - 0s 84us/sample - loss: 0.4222 - accuracy: 0.8083 - val_loss: 0.5292 - val_accuracy: 0.7640\n",
      "Epoch 30/40\n",
      "793/793 [==============================] - 0s 86us/sample - loss: 0.4213 - accuracy: 0.8096 - val_loss: 0.5287 - val_accuracy: 0.7640\n",
      "Epoch 31/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4210 - accuracy: 0.8096 - val_loss: 0.5288 - val_accuracy: 0.7640\n",
      "Epoch 32/40\n",
      "793/793 [==============================] - 0s 106us/sample - loss: 0.4203 - accuracy: 0.8108 - val_loss: 0.5297 - val_accuracy: 0.7753\n",
      "Epoch 33/40\n",
      "793/793 [==============================] - 0s 76us/sample - loss: 0.4197 - accuracy: 0.8108 - val_loss: 0.5323 - val_accuracy: 0.7753\n",
      "Epoch 34/40\n",
      "793/793 [==============================] - 0s 86us/sample - loss: 0.4189 - accuracy: 0.8096 - val_loss: 0.5294 - val_accuracy: 0.7753\n",
      "Epoch 35/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.4182 - accuracy: 0.8071 - val_loss: 0.5297 - val_accuracy: 0.7865\n",
      "Epoch 36/40\n",
      "793/793 [==============================] - 0s 83us/sample - loss: 0.4186 - accuracy: 0.8146 - val_loss: 0.5302 - val_accuracy: 0.7865\n",
      "Epoch 37/40\n",
      "793/793 [==============================] - 0s 84us/sample - loss: 0.4180 - accuracy: 0.8071 - val_loss: 0.5299 - val_accuracy: 0.7865\n",
      "Epoch 38/40\n",
      "793/793 [==============================] - 0s 80us/sample - loss: 0.4168 - accuracy: 0.8146 - val_loss: 0.5325 - val_accuracy: 0.7865\n",
      "Epoch 39/40\n",
      "793/793 [==============================] - 0s 88us/sample - loss: 0.4162 - accuracy: 0.8134 - val_loss: 0.5331 - val_accuracy: 0.7865\n",
      "Epoch 40/40\n",
      "793/793 [==============================] - 0s 80us/sample - loss: 0.4165 - accuracy: 0.8096 - val_loss: 0.5318 - val_accuracy: 0.7865\n",
      "Porcentagem de Acerto 53.29%\n",
      "Porcentagem de Acerto 0.0%\n",
      "Train on 793 samples, validate on 89 samples\n",
      "Epoch 1/40\n",
      "793/793 [==============================] - 0s 595us/sample - loss: 0.6687 - accuracy: 0.6141 - val_loss: 0.6487 - val_accuracy: 0.6180\n",
      "Epoch 2/40\n",
      "793/793 [==============================] - 0s 87us/sample - loss: 0.6179 - accuracy: 0.6545 - val_loss: 0.6215 - val_accuracy: 0.6854\n",
      "Epoch 3/40\n",
      "793/793 [==============================] - 0s 94us/sample - loss: 0.5783 - accuracy: 0.7919 - val_loss: 0.5945 - val_accuracy: 0.7079\n",
      "Epoch 4/40\n",
      "793/793 [==============================] - 0s 87us/sample - loss: 0.5367 - accuracy: 0.7982 - val_loss: 0.5713 - val_accuracy: 0.7191\n",
      "Epoch 5/40\n",
      "793/793 [==============================] - 0s 77us/sample - loss: 0.5047 - accuracy: 0.7907 - val_loss: 0.5537 - val_accuracy: 0.7416\n",
      "Epoch 6/40\n",
      "793/793 [==============================] - 0s 86us/sample - loss: 0.4807 - accuracy: 0.7945 - val_loss: 0.5436 - val_accuracy: 0.6966\n",
      "Epoch 7/40\n",
      "793/793 [==============================] - 0s 97us/sample - loss: 0.4640 - accuracy: 0.7945 - val_loss: 0.5405 - val_accuracy: 0.6966\n",
      "Epoch 8/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.4540 - accuracy: 0.7970 - val_loss: 0.5372 - val_accuracy: 0.7191\n",
      "Epoch 9/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.4463 - accuracy: 0.7995 - val_loss: 0.5416 - val_accuracy: 0.6966\n",
      "Epoch 10/40\n",
      "793/793 [==============================] - 0s 83us/sample - loss: 0.4428 - accuracy: 0.8008 - val_loss: 0.5384 - val_accuracy: 0.6966\n",
      "Epoch 11/40\n",
      "793/793 [==============================] - 0s 76us/sample - loss: 0.4400 - accuracy: 0.7982 - val_loss: 0.5365 - val_accuracy: 0.7191\n",
      "Epoch 12/40\n",
      "793/793 [==============================] - 0s 121us/sample - loss: 0.4365 - accuracy: 0.8033 - val_loss: 0.5370 - val_accuracy: 0.7191\n",
      "Epoch 13/40\n",
      "793/793 [==============================] - 0s 96us/sample - loss: 0.4322 - accuracy: 0.8058 - val_loss: 0.5332 - val_accuracy: 0.7303\n",
      "Epoch 14/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.4324 - accuracy: 0.8008 - val_loss: 0.5373 - val_accuracy: 0.7303\n",
      "Epoch 15/40\n",
      "793/793 [==============================] - 0s 109us/sample - loss: 0.4290 - accuracy: 0.8058 - val_loss: 0.5345 - val_accuracy: 0.7416\n",
      "Epoch 16/40\n",
      "793/793 [==============================] - 0s 73us/sample - loss: 0.4254 - accuracy: 0.8045 - val_loss: 0.5334 - val_accuracy: 0.7640\n",
      "Epoch 17/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4243 - accuracy: 0.8096 - val_loss: 0.5326 - val_accuracy: 0.7528\n",
      "Epoch 18/40\n",
      "793/793 [==============================] - 0s 79us/sample - loss: 0.4221 - accuracy: 0.8033 - val_loss: 0.5330 - val_accuracy: 0.7753\n",
      "Epoch 19/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4206 - accuracy: 0.8096 - val_loss: 0.5319 - val_accuracy: 0.7753\n",
      "Epoch 20/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.4195 - accuracy: 0.8083 - val_loss: 0.5310 - val_accuracy: 0.7528\n",
      "Epoch 21/40\n",
      "793/793 [==============================] - 0s 81us/sample - loss: 0.4187 - accuracy: 0.8020 - val_loss: 0.5329 - val_accuracy: 0.7528\n",
      "Epoch 22/40\n",
      "793/793 [==============================] - 0s 80us/sample - loss: 0.4171 - accuracy: 0.8083 - val_loss: 0.5321 - val_accuracy: 0.7528\n",
      "Epoch 23/40\n",
      "793/793 [==============================] - 0s 88us/sample - loss: 0.4172 - accuracy: 0.8083 - val_loss: 0.5321 - val_accuracy: 0.7640\n",
      "Epoch 24/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4151 - accuracy: 0.8083 - val_loss: 0.5290 - val_accuracy: 0.7753\n",
      "Epoch 25/40\n",
      "793/793 [==============================] - 0s 88us/sample - loss: 0.4141 - accuracy: 0.8108 - val_loss: 0.5311 - val_accuracy: 0.7753\n",
      "Epoch 26/40\n",
      "793/793 [==============================] - 0s 88us/sample - loss: 0.4148 - accuracy: 0.8134 - val_loss: 0.5309 - val_accuracy: 0.7753\n",
      "Epoch 27/40\n",
      "793/793 [==============================] - 0s 81us/sample - loss: 0.4128 - accuracy: 0.8159 - val_loss: 0.5328 - val_accuracy: 0.7753\n",
      "Epoch 28/40\n",
      "793/793 [==============================] - 0s 87us/sample - loss: 0.4117 - accuracy: 0.8209 - val_loss: 0.5321 - val_accuracy: 0.7753\n",
      "Epoch 29/40\n",
      "793/793 [==============================] - 0s 89us/sample - loss: 0.4117 - accuracy: 0.8197 - val_loss: 0.5310 - val_accuracy: 0.7865\n",
      "Epoch 30/40\n",
      "793/793 [==============================] - 0s 88us/sample - loss: 0.4108 - accuracy: 0.8134 - val_loss: 0.5311 - val_accuracy: 0.7865\n",
      "Epoch 31/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4115 - accuracy: 0.8209 - val_loss: 0.5337 - val_accuracy: 0.7865\n",
      "Epoch 32/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.4096 - accuracy: 0.8172 - val_loss: 0.5321 - val_accuracy: 0.7865\n",
      "Epoch 33/40\n",
      "793/793 [==============================] - 0s 88us/sample - loss: 0.4092 - accuracy: 0.8184 - val_loss: 0.5317 - val_accuracy: 0.7865\n",
      "Epoch 34/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.4084 - accuracy: 0.8209 - val_loss: 0.5325 - val_accuracy: 0.7865\n",
      "Epoch 35/40\n",
      "793/793 [==============================] - 0s 88us/sample - loss: 0.4080 - accuracy: 0.8197 - val_loss: 0.5334 - val_accuracy: 0.7865\n",
      "Epoch 36/40\n",
      "793/793 [==============================] - 0s 89us/sample - loss: 0.4075 - accuracy: 0.8247 - val_loss: 0.5329 - val_accuracy: 0.7865\n",
      "Epoch 37/40\n",
      "793/793 [==============================] - 0s 79us/sample - loss: 0.4075 - accuracy: 0.8184 - val_loss: 0.5329 - val_accuracy: 0.7865\n",
      "Epoch 38/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4073 - accuracy: 0.8209 - val_loss: 0.5347 - val_accuracy: 0.7865\n",
      "Epoch 39/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4075 - accuracy: 0.8172 - val_loss: 0.5348 - val_accuracy: 0.7865\n",
      "Epoch 40/40\n",
      "793/793 [==============================] - 0s 83us/sample - loss: 0.4074 - accuracy: 0.8235 - val_loss: 0.5311 - val_accuracy: 0.7865\n",
      "Porcentagem de Acerto 53.63%\n",
      "Porcentagem de Acerto 0.0%\n",
      "Train on 793 samples, validate on 89 samples\n",
      "Epoch 1/40\n",
      "793/793 [==============================] - 0s 596us/sample - loss: 0.6645 - accuracy: 0.6406 - val_loss: 0.6577 - val_accuracy: 0.6742\n",
      "Epoch 2/40\n",
      "793/793 [==============================] - 0s 77us/sample - loss: 0.6305 - accuracy: 0.7541 - val_loss: 0.6333 - val_accuracy: 0.7079\n",
      "Epoch 3/40\n",
      "793/793 [==============================] - 0s 80us/sample - loss: 0.5929 - accuracy: 0.7945 - val_loss: 0.6043 - val_accuracy: 0.7079\n",
      "Epoch 4/40\n",
      "793/793 [==============================] - 0s 89us/sample - loss: 0.5432 - accuracy: 0.7945 - val_loss: 0.5728 - val_accuracy: 0.7079\n",
      "Epoch 5/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.4956 - accuracy: 0.7945 - val_loss: 0.5584 - val_accuracy: 0.6966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/40\n",
      "793/793 [==============================] - 0s 89us/sample - loss: 0.4700 - accuracy: 0.7945 - val_loss: 0.5585 - val_accuracy: 0.6966\n",
      "Epoch 7/40\n",
      "793/793 [==============================] - 0s 85us/sample - loss: 0.4597 - accuracy: 0.7932 - val_loss: 0.5612 - val_accuracy: 0.6966\n",
      "Epoch 8/40\n",
      "793/793 [==============================] - 0s 79us/sample - loss: 0.4519 - accuracy: 0.7957 - val_loss: 0.5540 - val_accuracy: 0.6966\n",
      "Epoch 9/40\n",
      "793/793 [==============================] - 0s 87us/sample - loss: 0.4467 - accuracy: 0.7982 - val_loss: 0.5519 - val_accuracy: 0.6966\n",
      "Epoch 10/40\n",
      "793/793 [==============================] - 0s 78us/sample - loss: 0.4412 - accuracy: 0.8020 - val_loss: 0.5480 - val_accuracy: 0.6966\n",
      "Epoch 11/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.4377 - accuracy: 0.8020 - val_loss: 0.5462 - val_accuracy: 0.7191\n",
      "Epoch 12/40\n",
      "793/793 [==============================] - 0s 82us/sample - loss: 0.4353 - accuracy: 0.8020 - val_loss: 0.5412 - val_accuracy: 0.7303\n",
      "Epoch 13/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4349 - accuracy: 0.8045 - val_loss: 0.5416 - val_accuracy: 0.7640\n",
      "Epoch 14/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4284 - accuracy: 0.8045 - val_loss: 0.5413 - val_accuracy: 0.7416\n",
      "Epoch 15/40\n",
      "793/793 [==============================] - 0s 82us/sample - loss: 0.4275 - accuracy: 0.8071 - val_loss: 0.5399 - val_accuracy: 0.7753\n",
      "Epoch 16/40\n",
      "793/793 [==============================] - 0s 94us/sample - loss: 0.4260 - accuracy: 0.8071 - val_loss: 0.5410 - val_accuracy: 0.7416\n",
      "Epoch 17/40\n",
      "793/793 [==============================] - 0s 99us/sample - loss: 0.4236 - accuracy: 0.8096 - val_loss: 0.5415 - val_accuracy: 0.7753\n",
      "Epoch 18/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.4209 - accuracy: 0.8020 - val_loss: 0.5390 - val_accuracy: 0.7640\n",
      "Epoch 19/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4231 - accuracy: 0.7970 - val_loss: 0.5434 - val_accuracy: 0.7416\n",
      "Epoch 20/40\n",
      "793/793 [==============================] - 0s 82us/sample - loss: 0.4181 - accuracy: 0.8045 - val_loss: 0.5421 - val_accuracy: 0.7753\n",
      "Epoch 21/40\n",
      "793/793 [==============================] - 0s 88us/sample - loss: 0.4173 - accuracy: 0.8020 - val_loss: 0.5441 - val_accuracy: 0.7528\n",
      "Epoch 22/40\n",
      "793/793 [==============================] - 0s 78us/sample - loss: 0.4173 - accuracy: 0.8020 - val_loss: 0.5453 - val_accuracy: 0.7753\n",
      "Epoch 23/40\n",
      "793/793 [==============================] - 0s 85us/sample - loss: 0.4141 - accuracy: 0.8083 - val_loss: 0.5442 - val_accuracy: 0.7865\n",
      "Epoch 24/40\n",
      "793/793 [==============================] - 0s 87us/sample - loss: 0.4122 - accuracy: 0.8033 - val_loss: 0.5455 - val_accuracy: 0.7640\n",
      "Epoch 25/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.4118 - accuracy: 0.8083 - val_loss: 0.5468 - val_accuracy: 0.7753\n",
      "Epoch 26/40\n",
      "793/793 [==============================] - 0s 81us/sample - loss: 0.4118 - accuracy: 0.8096 - val_loss: 0.5438 - val_accuracy: 0.7640\n",
      "Epoch 27/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4110 - accuracy: 0.8096 - val_loss: 0.5437 - val_accuracy: 0.7753\n",
      "Epoch 28/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.4126 - accuracy: 0.8108 - val_loss: 0.5494 - val_accuracy: 0.7753\n",
      "Epoch 29/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.4106 - accuracy: 0.8134 - val_loss: 0.5464 - val_accuracy: 0.7753\n",
      "Epoch 30/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.4088 - accuracy: 0.8134 - val_loss: 0.5458 - val_accuracy: 0.7753\n",
      "Epoch 31/40\n",
      "793/793 [==============================] - 0s 82us/sample - loss: 0.4092 - accuracy: 0.8083 - val_loss: 0.5460 - val_accuracy: 0.7753\n",
      "Epoch 32/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4089 - accuracy: 0.8146 - val_loss: 0.5489 - val_accuracy: 0.7640\n",
      "Epoch 33/40\n",
      "793/793 [==============================] - 0s 94us/sample - loss: 0.4067 - accuracy: 0.8058 - val_loss: 0.5482 - val_accuracy: 0.7753\n",
      "Epoch 34/40\n",
      "793/793 [==============================] - 0s 89us/sample - loss: 0.4087 - accuracy: 0.8071 - val_loss: 0.5464 - val_accuracy: 0.7865\n",
      "Epoch 35/40\n",
      "793/793 [==============================] - 0s 97us/sample - loss: 0.4104 - accuracy: 0.8134 - val_loss: 0.5476 - val_accuracy: 0.7753\n",
      "Epoch 36/40\n",
      "793/793 [==============================] - 0s 89us/sample - loss: 0.4065 - accuracy: 0.8159 - val_loss: 0.5458 - val_accuracy: 0.7865\n",
      "Epoch 37/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4072 - accuracy: 0.8146 - val_loss: 0.5486 - val_accuracy: 0.7753\n",
      "Epoch 38/40\n",
      "793/793 [==============================] - 0s 87us/sample - loss: 0.4054 - accuracy: 0.8172 - val_loss: 0.5486 - val_accuracy: 0.7865\n",
      "Epoch 39/40\n",
      "793/793 [==============================] - 0s 78us/sample - loss: 0.4054 - accuracy: 0.8134 - val_loss: 0.5483 - val_accuracy: 0.7865\n",
      "Epoch 40/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4067 - accuracy: 0.8146 - val_loss: 0.5463 - val_accuracy: 0.7865\n",
      "Porcentagem de Acerto 53.06%\n",
      "Porcentagem de Acerto 0.0%\n",
      "Train on 793 samples, validate on 89 samples\n",
      "Epoch 1/40\n",
      "793/793 [==============================] - 0s 600us/sample - loss: 0.6858 - accuracy: 0.6204 - val_loss: 0.6551 - val_accuracy: 0.7079\n",
      "Epoch 2/40\n",
      "793/793 [==============================] - 0s 86us/sample - loss: 0.6086 - accuracy: 0.7932 - val_loss: 0.6092 - val_accuracy: 0.7079\n",
      "Epoch 3/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.5458 - accuracy: 0.7932 - val_loss: 0.5725 - val_accuracy: 0.7191\n",
      "Epoch 4/40\n",
      "793/793 [==============================] - 0s 96us/sample - loss: 0.4961 - accuracy: 0.7932 - val_loss: 0.5544 - val_accuracy: 0.6966\n",
      "Epoch 5/40\n",
      "793/793 [==============================] - 0s 79us/sample - loss: 0.4671 - accuracy: 0.7982 - val_loss: 0.5480 - val_accuracy: 0.6966\n",
      "Epoch 6/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4527 - accuracy: 0.7970 - val_loss: 0.5437 - val_accuracy: 0.6966\n",
      "Epoch 7/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.4430 - accuracy: 0.7995 - val_loss: 0.5419 - val_accuracy: 0.7528\n",
      "Epoch 8/40\n",
      "793/793 [==============================] - 0s 83us/sample - loss: 0.4377 - accuracy: 0.8008 - val_loss: 0.5357 - val_accuracy: 0.7416\n",
      "Epoch 9/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4338 - accuracy: 0.8045 - val_loss: 0.5307 - val_accuracy: 0.7528\n",
      "Epoch 10/40\n",
      "793/793 [==============================] - 0s 79us/sample - loss: 0.4290 - accuracy: 0.8008 - val_loss: 0.5343 - val_accuracy: 0.7528\n",
      "Epoch 11/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4264 - accuracy: 0.8033 - val_loss: 0.5312 - val_accuracy: 0.7865\n",
      "Epoch 12/40\n",
      "793/793 [==============================] - 0s 88us/sample - loss: 0.4252 - accuracy: 0.8058 - val_loss: 0.5277 - val_accuracy: 0.7753\n",
      "Epoch 13/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.4217 - accuracy: 0.8058 - val_loss: 0.5310 - val_accuracy: 0.7753\n",
      "Epoch 14/40\n",
      "793/793 [==============================] - 0s 77us/sample - loss: 0.4206 - accuracy: 0.8071 - val_loss: 0.5307 - val_accuracy: 0.7753\n",
      "Epoch 15/40\n",
      "793/793 [==============================] - 0s 80us/sample - loss: 0.4180 - accuracy: 0.8071 - val_loss: 0.5321 - val_accuracy: 0.7753\n",
      "Epoch 16/40\n",
      "793/793 [==============================] - 0s 97us/sample - loss: 0.4172 - accuracy: 0.8134 - val_loss: 0.5312 - val_accuracy: 0.7753\n",
      "Epoch 17/40\n",
      "793/793 [==============================] - 0s 75us/sample - loss: 0.4142 - accuracy: 0.8134 - val_loss: 0.5292 - val_accuracy: 0.7753\n",
      "Epoch 18/40\n",
      "793/793 [==============================] - 0s 73us/sample - loss: 0.4163 - accuracy: 0.8071 - val_loss: 0.5327 - val_accuracy: 0.7865\n",
      "Epoch 19/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.4161 - accuracy: 0.8134 - val_loss: 0.5318 - val_accuracy: 0.7865\n",
      "Epoch 20/40\n",
      "793/793 [==============================] - 0s 78us/sample - loss: 0.4125 - accuracy: 0.8159 - val_loss: 0.5326 - val_accuracy: 0.7978\n",
      "Epoch 21/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "793/793 [==============================] - 0s 86us/sample - loss: 0.4111 - accuracy: 0.8146 - val_loss: 0.5324 - val_accuracy: 0.7753\n",
      "Epoch 22/40\n",
      "793/793 [==============================] - 0s 80us/sample - loss: 0.4108 - accuracy: 0.8172 - val_loss: 0.5339 - val_accuracy: 0.7753\n",
      "Epoch 23/40\n",
      "793/793 [==============================] - 0s 88us/sample - loss: 0.4107 - accuracy: 0.8071 - val_loss: 0.5317 - val_accuracy: 0.7865\n",
      "Epoch 24/40\n",
      "793/793 [==============================] - 0s 79us/sample - loss: 0.4098 - accuracy: 0.8083 - val_loss: 0.5330 - val_accuracy: 0.7753\n",
      "Epoch 25/40\n",
      "793/793 [==============================] - 0s 81us/sample - loss: 0.4092 - accuracy: 0.8146 - val_loss: 0.5383 - val_accuracy: 0.7865\n",
      "Epoch 26/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4102 - accuracy: 0.8146 - val_loss: 0.5341 - val_accuracy: 0.7753\n",
      "Epoch 27/40\n",
      "793/793 [==============================] - 0s 79us/sample - loss: 0.4074 - accuracy: 0.8096 - val_loss: 0.5324 - val_accuracy: 0.7753\n",
      "Epoch 28/40\n",
      "793/793 [==============================] - 0s 89us/sample - loss: 0.4085 - accuracy: 0.8083 - val_loss: 0.5393 - val_accuracy: 0.7753\n",
      "Epoch 29/40\n",
      "793/793 [==============================] - 0s 76us/sample - loss: 0.4074 - accuracy: 0.8159 - val_loss: 0.5351 - val_accuracy: 0.7753\n",
      "Epoch 30/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.4076 - accuracy: 0.8096 - val_loss: 0.5342 - val_accuracy: 0.7978\n",
      "Epoch 31/40\n",
      "793/793 [==============================] - 0s 75us/sample - loss: 0.4073 - accuracy: 0.8108 - val_loss: 0.5343 - val_accuracy: 0.7753\n",
      "Epoch 32/40\n",
      "793/793 [==============================] - 0s 86us/sample - loss: 0.4063 - accuracy: 0.8146 - val_loss: 0.5405 - val_accuracy: 0.7753\n",
      "Epoch 33/40\n",
      "793/793 [==============================] - 0s 76us/sample - loss: 0.4043 - accuracy: 0.8184 - val_loss: 0.5378 - val_accuracy: 0.7753\n",
      "Epoch 34/40\n",
      "793/793 [==============================] - 0s 81us/sample - loss: 0.4059 - accuracy: 0.8083 - val_loss: 0.5387 - val_accuracy: 0.7865\n",
      "Epoch 35/40\n",
      "793/793 [==============================] - 0s 85us/sample - loss: 0.4077 - accuracy: 0.8146 - val_loss: 0.5390 - val_accuracy: 0.7865\n",
      "Epoch 36/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.4048 - accuracy: 0.8146 - val_loss: 0.5403 - val_accuracy: 0.7753\n",
      "Epoch 37/40\n",
      "793/793 [==============================] - 0s 94us/sample - loss: 0.4052 - accuracy: 0.8222 - val_loss: 0.5369 - val_accuracy: 0.7865\n",
      "Epoch 38/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4048 - accuracy: 0.8172 - val_loss: 0.5400 - val_accuracy: 0.7753\n",
      "Epoch 39/40\n",
      "793/793 [==============================] - 0s 79us/sample - loss: 0.4046 - accuracy: 0.8184 - val_loss: 0.5355 - val_accuracy: 0.7753\n",
      "Epoch 40/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.4034 - accuracy: 0.8197 - val_loss: 0.5393 - val_accuracy: 0.7753\n",
      "Porcentagem de Acerto 53.51%\n",
      "Porcentagem de Acerto 0.0%\n",
      "Train on 793 samples, validate on 89 samples\n",
      "Epoch 1/40\n",
      "793/793 [==============================] - 0s 606us/sample - loss: 0.6755 - accuracy: 0.5675 - val_loss: 0.6528 - val_accuracy: 0.6966\n",
      "Epoch 2/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.5989 - accuracy: 0.7654 - val_loss: 0.6092 - val_accuracy: 0.6966\n",
      "Epoch 3/40\n",
      "793/793 [==============================] - 0s 101us/sample - loss: 0.5331 - accuracy: 0.7932 - val_loss: 0.5667 - val_accuracy: 0.6966\n",
      "Epoch 4/40\n",
      "793/793 [==============================] - 0s 98us/sample - loss: 0.4759 - accuracy: 0.7982 - val_loss: 0.5427 - val_accuracy: 0.6966\n",
      "Epoch 5/40\n",
      "793/793 [==============================] - 0s 87us/sample - loss: 0.4498 - accuracy: 0.7982 - val_loss: 0.5412 - val_accuracy: 0.6966\n",
      "Epoch 6/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4406 - accuracy: 0.7982 - val_loss: 0.5385 - val_accuracy: 0.7416\n",
      "Epoch 7/40\n",
      "793/793 [==============================] - 0s 97us/sample - loss: 0.4377 - accuracy: 0.8058 - val_loss: 0.5363 - val_accuracy: 0.7640\n",
      "Epoch 8/40\n",
      "793/793 [==============================] - 0s 89us/sample - loss: 0.4349 - accuracy: 0.7970 - val_loss: 0.5339 - val_accuracy: 0.7640\n",
      "Epoch 9/40\n",
      "793/793 [==============================] - 0s 82us/sample - loss: 0.4308 - accuracy: 0.7982 - val_loss: 0.5356 - val_accuracy: 0.7416\n",
      "Epoch 10/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.4283 - accuracy: 0.8045 - val_loss: 0.5358 - val_accuracy: 0.7640\n",
      "Epoch 11/40\n",
      "793/793 [==============================] - 0s 86us/sample - loss: 0.4257 - accuracy: 0.8033 - val_loss: 0.5355 - val_accuracy: 0.7753\n",
      "Epoch 12/40\n",
      "793/793 [==============================] - 0s 87us/sample - loss: 0.4233 - accuracy: 0.8033 - val_loss: 0.5352 - val_accuracy: 0.7640\n",
      "Epoch 13/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.4206 - accuracy: 0.8159 - val_loss: 0.5360 - val_accuracy: 0.7640\n",
      "Epoch 14/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.4186 - accuracy: 0.8096 - val_loss: 0.5385 - val_accuracy: 0.7753\n",
      "Epoch 15/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4177 - accuracy: 0.8121 - val_loss: 0.5338 - val_accuracy: 0.7753\n",
      "Epoch 16/40\n",
      "793/793 [==============================] - 0s 104us/sample - loss: 0.4181 - accuracy: 0.8058 - val_loss: 0.5422 - val_accuracy: 0.7753\n",
      "Epoch 17/40\n",
      "793/793 [==============================] - 0s 72us/sample - loss: 0.4148 - accuracy: 0.8083 - val_loss: 0.5353 - val_accuracy: 0.7640\n",
      "Epoch 18/40\n",
      "793/793 [==============================] - 0s 82us/sample - loss: 0.4139 - accuracy: 0.8134 - val_loss: 0.5425 - val_accuracy: 0.7640\n",
      "Epoch 19/40\n",
      "793/793 [==============================] - 0s 89us/sample - loss: 0.4136 - accuracy: 0.8058 - val_loss: 0.5408 - val_accuracy: 0.7753\n",
      "Epoch 20/40\n",
      "793/793 [==============================] - 0s 111us/sample - loss: 0.4116 - accuracy: 0.8146 - val_loss: 0.5387 - val_accuracy: 0.7865\n",
      "Epoch 21/40\n",
      "793/793 [==============================] - 0s 78us/sample - loss: 0.4112 - accuracy: 0.8134 - val_loss: 0.5410 - val_accuracy: 0.7865\n",
      "Epoch 22/40\n",
      "793/793 [==============================] - 0s 78us/sample - loss: 0.4096 - accuracy: 0.8071 - val_loss: 0.5440 - val_accuracy: 0.7753\n",
      "Epoch 23/40\n",
      "793/793 [==============================] - 0s 94us/sample - loss: 0.4120 - accuracy: 0.8071 - val_loss: 0.5378 - val_accuracy: 0.7978\n",
      "Epoch 24/40\n",
      "793/793 [==============================] - 0s 87us/sample - loss: 0.4088 - accuracy: 0.8121 - val_loss: 0.5435 - val_accuracy: 0.7865\n",
      "Epoch 25/40\n",
      "793/793 [==============================] - 0s 81us/sample - loss: 0.4096 - accuracy: 0.8146 - val_loss: 0.5445 - val_accuracy: 0.7753\n",
      "Epoch 26/40\n",
      "793/793 [==============================] - 0s 89us/sample - loss: 0.4082 - accuracy: 0.8096 - val_loss: 0.5431 - val_accuracy: 0.7865\n",
      "Epoch 27/40\n",
      "793/793 [==============================] - 0s 79us/sample - loss: 0.4070 - accuracy: 0.8159 - val_loss: 0.5454 - val_accuracy: 0.7865\n",
      "Epoch 28/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4062 - accuracy: 0.8159 - val_loss: 0.5430 - val_accuracy: 0.7865\n",
      "Epoch 29/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.4121 - accuracy: 0.8121 - val_loss: 0.5407 - val_accuracy: 0.7753\n",
      "Epoch 30/40\n",
      "793/793 [==============================] - 0s 87us/sample - loss: 0.4075 - accuracy: 0.8096 - val_loss: 0.5439 - val_accuracy: 0.7865\n",
      "Epoch 31/40\n",
      "793/793 [==============================] - 0s 86us/sample - loss: 0.4065 - accuracy: 0.8209 - val_loss: 0.5446 - val_accuracy: 0.7865\n",
      "Epoch 32/40\n",
      "793/793 [==============================] - 0s 96us/sample - loss: 0.4050 - accuracy: 0.8159 - val_loss: 0.5455 - val_accuracy: 0.7865\n",
      "Epoch 33/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.4044 - accuracy: 0.8247 - val_loss: 0.5440 - val_accuracy: 0.7978\n",
      "Epoch 34/40\n",
      "793/793 [==============================] - 0s 80us/sample - loss: 0.4040 - accuracy: 0.8235 - val_loss: 0.5447 - val_accuracy: 0.7865\n",
      "Epoch 35/40\n",
      "793/793 [==============================] - 0s 80us/sample - loss: 0.4029 - accuracy: 0.8285 - val_loss: 0.5422 - val_accuracy: 0.7865\n",
      "Epoch 36/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "793/793 [==============================] - 0s 95us/sample - loss: 0.4032 - accuracy: 0.8209 - val_loss: 0.5451 - val_accuracy: 0.7753\n",
      "Epoch 37/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4050 - accuracy: 0.8184 - val_loss: 0.5464 - val_accuracy: 0.7753\n",
      "Epoch 38/40\n",
      "793/793 [==============================] - 0s 88us/sample - loss: 0.4034 - accuracy: 0.8260 - val_loss: 0.5413 - val_accuracy: 0.7753\n",
      "Epoch 39/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4022 - accuracy: 0.8310 - val_loss: 0.5464 - val_accuracy: 0.7865\n",
      "Epoch 40/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4027 - accuracy: 0.8197 - val_loss: 0.5467 - val_accuracy: 0.7865\n",
      "Porcentagem de Acerto 52.95%\n",
      "Porcentagem de Acerto 0.0%\n",
      "Train on 793 samples, validate on 89 samples\n",
      "Epoch 1/40\n",
      "793/793 [==============================] - 0s 595us/sample - loss: 0.6311 - accuracy: 0.7339 - val_loss: 0.6045 - val_accuracy: 0.7079\n",
      "Epoch 2/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.5326 - accuracy: 0.7982 - val_loss: 0.5590 - val_accuracy: 0.7528\n",
      "Epoch 3/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.4813 - accuracy: 0.7932 - val_loss: 0.5462 - val_accuracy: 0.6966\n",
      "Epoch 4/40\n",
      "793/793 [==============================] - 0s 105us/sample - loss: 0.4602 - accuracy: 0.7970 - val_loss: 0.5441 - val_accuracy: 0.7191\n",
      "Epoch 5/40\n",
      "793/793 [==============================] - 0s 103us/sample - loss: 0.4481 - accuracy: 0.7995 - val_loss: 0.5416 - val_accuracy: 0.7191\n",
      "Epoch 6/40\n",
      "793/793 [==============================] - 0s 86us/sample - loss: 0.4400 - accuracy: 0.7982 - val_loss: 0.5387 - val_accuracy: 0.7303\n",
      "Epoch 7/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4353 - accuracy: 0.8033 - val_loss: 0.5399 - val_accuracy: 0.7416\n",
      "Epoch 8/40\n",
      "793/793 [==============================] - 0s 82us/sample - loss: 0.4291 - accuracy: 0.8020 - val_loss: 0.5388 - val_accuracy: 0.7640\n",
      "Epoch 9/40\n",
      "793/793 [==============================] - 0s 78us/sample - loss: 0.4272 - accuracy: 0.8083 - val_loss: 0.5418 - val_accuracy: 0.7528\n",
      "Epoch 10/40\n",
      "793/793 [==============================] - 0s 84us/sample - loss: 0.4214 - accuracy: 0.7970 - val_loss: 0.5376 - val_accuracy: 0.7753\n",
      "Epoch 11/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.4202 - accuracy: 0.8108 - val_loss: 0.5396 - val_accuracy: 0.7528\n",
      "Epoch 12/40\n",
      "793/793 [==============================] - 0s 80us/sample - loss: 0.4145 - accuracy: 0.8020 - val_loss: 0.5452 - val_accuracy: 0.7640\n",
      "Epoch 13/40\n",
      "793/793 [==============================] - 0s 88us/sample - loss: 0.4193 - accuracy: 0.8033 - val_loss: 0.5403 - val_accuracy: 0.7753\n",
      "Epoch 14/40\n",
      "793/793 [==============================] - 0s 79us/sample - loss: 0.4140 - accuracy: 0.8083 - val_loss: 0.5383 - val_accuracy: 0.7865\n",
      "Epoch 15/40\n",
      "793/793 [==============================] - 0s 97us/sample - loss: 0.4118 - accuracy: 0.8172 - val_loss: 0.5400 - val_accuracy: 0.7640\n",
      "Epoch 16/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.4118 - accuracy: 0.8096 - val_loss: 0.5431 - val_accuracy: 0.7640\n",
      "Epoch 17/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.4156 - accuracy: 0.8020 - val_loss: 0.5436 - val_accuracy: 0.7640\n",
      "Epoch 18/40\n",
      "793/793 [==============================] - 0s 87us/sample - loss: 0.4076 - accuracy: 0.8083 - val_loss: 0.5412 - val_accuracy: 0.7865\n",
      "Epoch 19/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.4097 - accuracy: 0.8184 - val_loss: 0.5417 - val_accuracy: 0.7865\n",
      "Epoch 20/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.4071 - accuracy: 0.8184 - val_loss: 0.5403 - val_accuracy: 0.7865\n",
      "Epoch 21/40\n",
      "793/793 [==============================] - 0s 86us/sample - loss: 0.4066 - accuracy: 0.8184 - val_loss: 0.5402 - val_accuracy: 0.7753\n",
      "Epoch 22/40\n",
      "793/793 [==============================] - 0s 79us/sample - loss: 0.4068 - accuracy: 0.8209 - val_loss: 0.5398 - val_accuracy: 0.7865\n",
      "Epoch 23/40\n",
      "793/793 [==============================] - 0s 89us/sample - loss: 0.4057 - accuracy: 0.8159 - val_loss: 0.5420 - val_accuracy: 0.7865\n",
      "Epoch 24/40\n",
      "793/793 [==============================] - 0s 99us/sample - loss: 0.4058 - accuracy: 0.8096 - val_loss: 0.5483 - val_accuracy: 0.7753\n",
      "Epoch 25/40\n",
      "793/793 [==============================] - 0s 94us/sample - loss: 0.4092 - accuracy: 0.8134 - val_loss: 0.5447 - val_accuracy: 0.7978\n",
      "Epoch 26/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.4061 - accuracy: 0.8197 - val_loss: 0.5437 - val_accuracy: 0.7753\n",
      "Epoch 27/40\n",
      "793/793 [==============================] - 0s 88us/sample - loss: 0.4088 - accuracy: 0.8235 - val_loss: 0.5415 - val_accuracy: 0.7978\n",
      "Epoch 28/40\n",
      "793/793 [==============================] - 0s 80us/sample - loss: 0.4037 - accuracy: 0.8197 - val_loss: 0.5416 - val_accuracy: 0.7865\n",
      "Epoch 29/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.4034 - accuracy: 0.8159 - val_loss: 0.5409 - val_accuracy: 0.7978\n",
      "Epoch 30/40\n",
      "793/793 [==============================] - 0s 88us/sample - loss: 0.4056 - accuracy: 0.8172 - val_loss: 0.5475 - val_accuracy: 0.7753\n",
      "Epoch 31/40\n",
      "793/793 [==============================] - 0s 94us/sample - loss: 0.4048 - accuracy: 0.8146 - val_loss: 0.5422 - val_accuracy: 0.7753\n",
      "Epoch 32/40\n",
      "793/793 [==============================] - 0s 97us/sample - loss: 0.4041 - accuracy: 0.8172 - val_loss: 0.5401 - val_accuracy: 0.7865\n",
      "Epoch 33/40\n",
      "793/793 [==============================] - 0s 94us/sample - loss: 0.4038 - accuracy: 0.8172 - val_loss: 0.5399 - val_accuracy: 0.7865\n",
      "Epoch 34/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.4040 - accuracy: 0.8172 - val_loss: 0.5434 - val_accuracy: 0.7865\n",
      "Epoch 35/40\n",
      "793/793 [==============================] - 0s 80us/sample - loss: 0.4016 - accuracy: 0.8197 - val_loss: 0.5390 - val_accuracy: 0.7865\n",
      "Epoch 36/40\n",
      "793/793 [==============================] - 0s 79us/sample - loss: 0.4052 - accuracy: 0.8272 - val_loss: 0.5384 - val_accuracy: 0.8090\n",
      "Epoch 37/40\n",
      "793/793 [==============================] - 0s 84us/sample - loss: 0.3997 - accuracy: 0.8260 - val_loss: 0.5442 - val_accuracy: 0.7978\n",
      "Epoch 38/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.4014 - accuracy: 0.8247 - val_loss: 0.5413 - val_accuracy: 0.7865\n",
      "Epoch 39/40\n",
      "793/793 [==============================] - 0s 83us/sample - loss: 0.4014 - accuracy: 0.8184 - val_loss: 0.5390 - val_accuracy: 0.8090\n",
      "Epoch 40/40\n",
      "793/793 [==============================] - 0s 73us/sample - loss: 0.4017 - accuracy: 0.8260 - val_loss: 0.5393 - val_accuracy: 0.7865\n",
      "Porcentagem de Acerto 52.83%\n",
      "Porcentagem de Acerto 0.0%\n",
      "Train on 793 samples, validate on 89 samples\n",
      "Epoch 1/40\n",
      "793/793 [==============================] - 0s 608us/sample - loss: 0.6362 - accuracy: 0.6368 - val_loss: 0.6204 - val_accuracy: 0.6629\n",
      "Epoch 2/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.5549 - accuracy: 0.7680 - val_loss: 0.5757 - val_accuracy: 0.6966\n",
      "Epoch 3/40\n",
      "793/793 [==============================] - 0s 77us/sample - loss: 0.4973 - accuracy: 0.7945 - val_loss: 0.5561 - val_accuracy: 0.7303\n",
      "Epoch 4/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.4673 - accuracy: 0.7982 - val_loss: 0.5511 - val_accuracy: 0.7079\n",
      "Epoch 5/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.4515 - accuracy: 0.7945 - val_loss: 0.5499 - val_accuracy: 0.6966\n",
      "Epoch 6/40\n",
      "793/793 [==============================] - 0s 79us/sample - loss: 0.4424 - accuracy: 0.7995 - val_loss: 0.5497 - val_accuracy: 0.7079\n",
      "Epoch 7/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4334 - accuracy: 0.7982 - val_loss: 0.5361 - val_accuracy: 0.7416\n",
      "Epoch 8/40\n",
      "793/793 [==============================] - 0s 94us/sample - loss: 0.4296 - accuracy: 0.8008 - val_loss: 0.5369 - val_accuracy: 0.7416\n",
      "Epoch 9/40\n",
      "793/793 [==============================] - 0s 85us/sample - loss: 0.4240 - accuracy: 0.8020 - val_loss: 0.5358 - val_accuracy: 0.7753\n",
      "Epoch 10/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.4212 - accuracy: 0.8008 - val_loss: 0.5347 - val_accuracy: 0.7640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.4197 - accuracy: 0.7957 - val_loss: 0.5339 - val_accuracy: 0.7640\n",
      "Epoch 12/40\n",
      "793/793 [==============================] - 0s 82us/sample - loss: 0.4175 - accuracy: 0.8033 - val_loss: 0.5338 - val_accuracy: 0.7753\n",
      "Epoch 13/40\n",
      "793/793 [==============================] - 0s 85us/sample - loss: 0.4157 - accuracy: 0.8020 - val_loss: 0.5362 - val_accuracy: 0.7640\n",
      "Epoch 14/40\n",
      "793/793 [==============================] - 0s 89us/sample - loss: 0.4175 - accuracy: 0.7995 - val_loss: 0.5372 - val_accuracy: 0.7640\n",
      "Epoch 15/40\n",
      "793/793 [==============================] - 0s 88us/sample - loss: 0.4128 - accuracy: 0.8045 - val_loss: 0.5327 - val_accuracy: 0.7753\n",
      "Epoch 16/40\n",
      "793/793 [==============================] - 0s 86us/sample - loss: 0.4123 - accuracy: 0.8071 - val_loss: 0.5356 - val_accuracy: 0.7640\n",
      "Epoch 17/40\n",
      "793/793 [==============================] - 0s 87us/sample - loss: 0.4109 - accuracy: 0.8045 - val_loss: 0.5375 - val_accuracy: 0.7753\n",
      "Epoch 18/40\n",
      "793/793 [==============================] - 0s 79us/sample - loss: 0.4108 - accuracy: 0.8058 - val_loss: 0.5352 - val_accuracy: 0.7640\n",
      "Epoch 19/40\n",
      "793/793 [==============================] - 0s 87us/sample - loss: 0.4096 - accuracy: 0.8071 - val_loss: 0.5423 - val_accuracy: 0.7865\n",
      "Epoch 20/40\n",
      "793/793 [==============================] - 0s 85us/sample - loss: 0.4100 - accuracy: 0.8058 - val_loss: 0.5345 - val_accuracy: 0.7640\n",
      "Epoch 21/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4090 - accuracy: 0.8071 - val_loss: 0.5355 - val_accuracy: 0.7978\n",
      "Epoch 22/40\n",
      "793/793 [==============================] - 0s 89us/sample - loss: 0.4104 - accuracy: 0.8108 - val_loss: 0.5391 - val_accuracy: 0.7865\n",
      "Epoch 23/40\n",
      "793/793 [==============================] - 0s 85us/sample - loss: 0.4087 - accuracy: 0.8071 - val_loss: 0.5359 - val_accuracy: 0.7640\n",
      "Epoch 24/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4071 - accuracy: 0.8134 - val_loss: 0.5391 - val_accuracy: 0.7865\n",
      "Epoch 25/40\n",
      "793/793 [==============================] - 0s 88us/sample - loss: 0.4095 - accuracy: 0.8108 - val_loss: 0.5380 - val_accuracy: 0.7978\n",
      "Epoch 26/40\n",
      "793/793 [==============================] - 0s 81us/sample - loss: 0.4051 - accuracy: 0.8197 - val_loss: 0.5373 - val_accuracy: 0.7865\n",
      "Epoch 27/40\n",
      "793/793 [==============================] - 0s 98us/sample - loss: 0.4051 - accuracy: 0.8172 - val_loss: 0.5329 - val_accuracy: 0.7865\n",
      "Epoch 28/40\n",
      "793/793 [==============================] - 0s 89us/sample - loss: 0.4083 - accuracy: 0.8121 - val_loss: 0.5377 - val_accuracy: 0.7865\n",
      "Epoch 29/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4056 - accuracy: 0.8184 - val_loss: 0.5389 - val_accuracy: 0.7753\n",
      "Epoch 30/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4067 - accuracy: 0.8209 - val_loss: 0.5412 - val_accuracy: 0.7753\n",
      "Epoch 31/40\n",
      "793/793 [==============================] - 0s 87us/sample - loss: 0.4100 - accuracy: 0.8045 - val_loss: 0.5393 - val_accuracy: 0.7978\n",
      "Epoch 32/40\n",
      "793/793 [==============================] - 0s 87us/sample - loss: 0.4040 - accuracy: 0.8184 - val_loss: 0.5384 - val_accuracy: 0.7865\n",
      "Epoch 33/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.4047 - accuracy: 0.8222 - val_loss: 0.5330 - val_accuracy: 0.7978\n",
      "Epoch 34/40\n",
      "793/793 [==============================] - 0s 88us/sample - loss: 0.4031 - accuracy: 0.8247 - val_loss: 0.5356 - val_accuracy: 0.7865\n",
      "Epoch 35/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4036 - accuracy: 0.8146 - val_loss: 0.5338 - val_accuracy: 0.7865\n",
      "Epoch 36/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4071 - accuracy: 0.8121 - val_loss: 0.5372 - val_accuracy: 0.7865\n",
      "Epoch 37/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4034 - accuracy: 0.8247 - val_loss: 0.5379 - val_accuracy: 0.7865\n",
      "Epoch 38/40\n",
      "793/793 [==============================] - 0s 100us/sample - loss: 0.4037 - accuracy: 0.8184 - val_loss: 0.5295 - val_accuracy: 0.8090\n",
      "Epoch 39/40\n",
      "793/793 [==============================] - 0s 82us/sample - loss: 0.4031 - accuracy: 0.8184 - val_loss: 0.5377 - val_accuracy: 0.7978\n",
      "Epoch 40/40\n",
      "793/793 [==============================] - 0s 82us/sample - loss: 0.4023 - accuracy: 0.8222 - val_loss: 0.5367 - val_accuracy: 0.7978\n",
      "Porcentagem de Acerto 53.4%\n",
      "Porcentagem de Acerto 0.0%\n",
      "Train on 793 samples, validate on 89 samples\n",
      "Epoch 1/40\n",
      "793/793 [==============================] - 0s 614us/sample - loss: 0.6377 - accuracy: 0.6381 - val_loss: 0.6117 - val_accuracy: 0.6629\n",
      "Epoch 2/40\n",
      "793/793 [==============================] - 0s 99us/sample - loss: 0.5455 - accuracy: 0.7755 - val_loss: 0.5622 - val_accuracy: 0.7528\n",
      "Epoch 3/40\n",
      "793/793 [==============================] - 0s 94us/sample - loss: 0.4832 - accuracy: 0.8083 - val_loss: 0.5451 - val_accuracy: 0.7416\n",
      "Epoch 4/40\n",
      "793/793 [==============================] - 0s 98us/sample - loss: 0.4545 - accuracy: 0.7995 - val_loss: 0.5423 - val_accuracy: 0.7191\n",
      "Epoch 5/40\n",
      "793/793 [==============================] - 0s 96us/sample - loss: 0.4429 - accuracy: 0.7995 - val_loss: 0.5421 - val_accuracy: 0.7191\n",
      "Epoch 6/40\n",
      "793/793 [==============================] - 0s 94us/sample - loss: 0.4354 - accuracy: 0.8033 - val_loss: 0.5407 - val_accuracy: 0.7191\n",
      "Epoch 7/40\n",
      "793/793 [==============================] - 0s 77us/sample - loss: 0.4320 - accuracy: 0.8008 - val_loss: 0.5372 - val_accuracy: 0.7416\n",
      "Epoch 8/40\n",
      "793/793 [==============================] - 0s 89us/sample - loss: 0.4265 - accuracy: 0.8008 - val_loss: 0.5385 - val_accuracy: 0.7528\n",
      "Epoch 9/40\n",
      "793/793 [==============================] - 0s 96us/sample - loss: 0.4224 - accuracy: 0.8058 - val_loss: 0.5375 - val_accuracy: 0.7640\n",
      "Epoch 10/40\n",
      "793/793 [==============================] - 0s 84us/sample - loss: 0.4204 - accuracy: 0.8083 - val_loss: 0.5401 - val_accuracy: 0.7753\n",
      "Epoch 11/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.4187 - accuracy: 0.8045 - val_loss: 0.5439 - val_accuracy: 0.7640\n",
      "Epoch 12/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.4220 - accuracy: 0.7932 - val_loss: 0.5453 - val_accuracy: 0.7528\n",
      "Epoch 13/40\n",
      "793/793 [==============================] - 0s 74us/sample - loss: 0.4206 - accuracy: 0.8020 - val_loss: 0.5442 - val_accuracy: 0.7753\n",
      "Epoch 14/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.4143 - accuracy: 0.8083 - val_loss: 0.5420 - val_accuracy: 0.7753\n",
      "Epoch 15/40\n",
      "793/793 [==============================] - 0s 79us/sample - loss: 0.4131 - accuracy: 0.8096 - val_loss: 0.5419 - val_accuracy: 0.7753\n",
      "Epoch 16/40\n",
      "793/793 [==============================] - 0s 88us/sample - loss: 0.4107 - accuracy: 0.8134 - val_loss: 0.5420 - val_accuracy: 0.7640\n",
      "Epoch 17/40\n",
      "793/793 [==============================] - 0s 97us/sample - loss: 0.4094 - accuracy: 0.8008 - val_loss: 0.5453 - val_accuracy: 0.7753\n",
      "Epoch 18/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4099 - accuracy: 0.8159 - val_loss: 0.5470 - val_accuracy: 0.7978\n",
      "Epoch 19/40\n",
      "793/793 [==============================] - 0s 89us/sample - loss: 0.4091 - accuracy: 0.8058 - val_loss: 0.5437 - val_accuracy: 0.7640\n",
      "Epoch 20/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4085 - accuracy: 0.8121 - val_loss: 0.5418 - val_accuracy: 0.7865\n",
      "Epoch 21/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4091 - accuracy: 0.8083 - val_loss: 0.5396 - val_accuracy: 0.7753\n",
      "Epoch 22/40\n",
      "793/793 [==============================] - 0s 85us/sample - loss: 0.4059 - accuracy: 0.8134 - val_loss: 0.5525 - val_accuracy: 0.7753\n",
      "Epoch 23/40\n",
      "793/793 [==============================] - 0s 88us/sample - loss: 0.4088 - accuracy: 0.8134 - val_loss: 0.5458 - val_accuracy: 0.7753\n",
      "Epoch 24/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.4041 - accuracy: 0.8197 - val_loss: 0.5436 - val_accuracy: 0.7978\n",
      "Epoch 25/40\n",
      "793/793 [==============================] - 0s 99us/sample - loss: 0.4034 - accuracy: 0.8184 - val_loss: 0.5416 - val_accuracy: 0.7865\n",
      "Epoch 26/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "793/793 [==============================] - 0s 90us/sample - loss: 0.4043 - accuracy: 0.8184 - val_loss: 0.5445 - val_accuracy: 0.7753\n",
      "Epoch 27/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.4028 - accuracy: 0.8197 - val_loss: 0.5505 - val_accuracy: 0.7753\n",
      "Epoch 28/40\n",
      "793/793 [==============================] - 0s 81us/sample - loss: 0.4049 - accuracy: 0.8134 - val_loss: 0.5435 - val_accuracy: 0.7865\n",
      "Epoch 29/40\n",
      "793/793 [==============================] - 0s 86us/sample - loss: 0.4021 - accuracy: 0.8159 - val_loss: 0.5439 - val_accuracy: 0.7978\n",
      "Epoch 30/40\n",
      "793/793 [==============================] - 0s 87us/sample - loss: 0.4051 - accuracy: 0.8222 - val_loss: 0.5431 - val_accuracy: 0.7753\n",
      "Epoch 31/40\n",
      "793/793 [==============================] - 0s 89us/sample - loss: 0.3984 - accuracy: 0.8298 - val_loss: 0.5405 - val_accuracy: 0.7865\n",
      "Epoch 32/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.4009 - accuracy: 0.8222 - val_loss: 0.5425 - val_accuracy: 0.7978\n",
      "Epoch 33/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.4007 - accuracy: 0.8260 - val_loss: 0.5369 - val_accuracy: 0.7753\n",
      "Epoch 34/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.3966 - accuracy: 0.8310 - val_loss: 0.5457 - val_accuracy: 0.7978\n",
      "Epoch 35/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.3984 - accuracy: 0.8260 - val_loss: 0.5395 - val_accuracy: 0.7865\n",
      "Epoch 36/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.3967 - accuracy: 0.8247 - val_loss: 0.5429 - val_accuracy: 0.7865\n",
      "Epoch 37/40\n",
      "793/793 [==============================] - 0s 86us/sample - loss: 0.3974 - accuracy: 0.8348 - val_loss: 0.5444 - val_accuracy: 0.7753\n",
      "Epoch 38/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.3971 - accuracy: 0.8298 - val_loss: 0.5455 - val_accuracy: 0.7978\n",
      "Epoch 39/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.3958 - accuracy: 0.8285 - val_loss: 0.5507 - val_accuracy: 0.7865\n",
      "Epoch 40/40\n",
      "793/793 [==============================] - 0s 80us/sample - loss: 0.3965 - accuracy: 0.8285 - val_loss: 0.5372 - val_accuracy: 0.7640\n",
      "Porcentagem de Acerto 50.91%\n",
      "Porcentagem de Acerto 0.0%\n",
      "Train on 793 samples, validate on 89 samples\n",
      "Epoch 1/40\n",
      "793/793 [==============================] - 0s 601us/sample - loss: 0.6232 - accuracy: 0.7402 - val_loss: 0.5991 - val_accuracy: 0.7079\n",
      "Epoch 2/40\n",
      "793/793 [==============================] - 0s 88us/sample - loss: 0.5225 - accuracy: 0.8008 - val_loss: 0.5569 - val_accuracy: 0.6966\n",
      "Epoch 3/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4620 - accuracy: 0.7957 - val_loss: 0.5416 - val_accuracy: 0.6966\n",
      "Epoch 4/40\n",
      "793/793 [==============================] - 0s 84us/sample - loss: 0.4438 - accuracy: 0.7982 - val_loss: 0.5385 - val_accuracy: 0.7753\n",
      "Epoch 5/40\n",
      "793/793 [==============================] - 0s 96us/sample - loss: 0.4386 - accuracy: 0.8008 - val_loss: 0.5358 - val_accuracy: 0.7753\n",
      "Epoch 6/40\n",
      "793/793 [==============================] - 0s 84us/sample - loss: 0.4320 - accuracy: 0.8033 - val_loss: 0.5359 - val_accuracy: 0.7528\n",
      "Epoch 7/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4292 - accuracy: 0.7957 - val_loss: 0.5393 - val_accuracy: 0.7303\n",
      "Epoch 8/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4228 - accuracy: 0.8108 - val_loss: 0.5430 - val_accuracy: 0.7528\n",
      "Epoch 9/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4203 - accuracy: 0.8071 - val_loss: 0.5372 - val_accuracy: 0.7416\n",
      "Epoch 10/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4260 - accuracy: 0.7932 - val_loss: 0.5307 - val_accuracy: 0.7753\n",
      "Epoch 11/40\n",
      "793/793 [==============================] - 0s 83us/sample - loss: 0.4189 - accuracy: 0.8071 - val_loss: 0.5343 - val_accuracy: 0.7640\n",
      "Epoch 12/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.4157 - accuracy: 0.8071 - val_loss: 0.5398 - val_accuracy: 0.7640\n",
      "Epoch 13/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4130 - accuracy: 0.8108 - val_loss: 0.5381 - val_accuracy: 0.7753\n",
      "Epoch 14/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.4138 - accuracy: 0.8146 - val_loss: 0.5334 - val_accuracy: 0.7753\n",
      "Epoch 15/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4141 - accuracy: 0.8146 - val_loss: 0.5349 - val_accuracy: 0.7865\n",
      "Epoch 16/40\n",
      "793/793 [==============================] - 0s 87us/sample - loss: 0.4110 - accuracy: 0.8083 - val_loss: 0.5339 - val_accuracy: 0.7978\n",
      "Epoch 17/40\n",
      "793/793 [==============================] - 0s 98us/sample - loss: 0.4122 - accuracy: 0.8159 - val_loss: 0.5346 - val_accuracy: 0.7978\n",
      "Epoch 18/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.4109 - accuracy: 0.8159 - val_loss: 0.5391 - val_accuracy: 0.7865\n",
      "Epoch 19/40\n",
      "793/793 [==============================] - 0s 84us/sample - loss: 0.4131 - accuracy: 0.8146 - val_loss: 0.5403 - val_accuracy: 0.7978\n",
      "Epoch 20/40\n",
      "793/793 [==============================] - 0s 94us/sample - loss: 0.4097 - accuracy: 0.8159 - val_loss: 0.5376 - val_accuracy: 0.7865\n",
      "Epoch 21/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.4053 - accuracy: 0.8209 - val_loss: 0.5389 - val_accuracy: 0.7865\n",
      "Epoch 22/40\n",
      "793/793 [==============================] - 0s 88us/sample - loss: 0.4058 - accuracy: 0.8134 - val_loss: 0.5360 - val_accuracy: 0.7865\n",
      "Epoch 23/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.4049 - accuracy: 0.8184 - val_loss: 0.5392 - val_accuracy: 0.7865\n",
      "Epoch 24/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4058 - accuracy: 0.8172 - val_loss: 0.5409 - val_accuracy: 0.7753\n",
      "Epoch 25/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4082 - accuracy: 0.8260 - val_loss: 0.5393 - val_accuracy: 0.7865\n",
      "Epoch 26/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.4058 - accuracy: 0.8134 - val_loss: 0.5402 - val_accuracy: 0.7978\n",
      "Epoch 27/40\n",
      "793/793 [==============================] - 0s 82us/sample - loss: 0.4037 - accuracy: 0.8197 - val_loss: 0.5417 - val_accuracy: 0.7753\n",
      "Epoch 28/40\n",
      "793/793 [==============================] - 0s 78us/sample - loss: 0.4030 - accuracy: 0.8146 - val_loss: 0.5350 - val_accuracy: 0.8090\n",
      "Epoch 29/40\n",
      "793/793 [==============================] - 0s 94us/sample - loss: 0.4032 - accuracy: 0.8260 - val_loss: 0.5376 - val_accuracy: 0.7978\n",
      "Epoch 30/40\n",
      "793/793 [==============================] - 0s 86us/sample - loss: 0.4036 - accuracy: 0.8197 - val_loss: 0.5440 - val_accuracy: 0.7865\n",
      "Epoch 31/40\n",
      "793/793 [==============================] - 0s 89us/sample - loss: 0.4034 - accuracy: 0.8121 - val_loss: 0.5457 - val_accuracy: 0.7528\n",
      "Epoch 32/40\n",
      "793/793 [==============================] - 0s 80us/sample - loss: 0.4069 - accuracy: 0.8197 - val_loss: 0.5351 - val_accuracy: 0.7978\n",
      "Epoch 33/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.4021 - accuracy: 0.8323 - val_loss: 0.5406 - val_accuracy: 0.7753\n",
      "Epoch 34/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.4041 - accuracy: 0.8159 - val_loss: 0.5375 - val_accuracy: 0.7865\n",
      "Epoch 35/40\n",
      "793/793 [==============================] - 0s 86us/sample - loss: 0.4064 - accuracy: 0.8197 - val_loss: 0.5395 - val_accuracy: 0.7640\n",
      "Epoch 36/40\n",
      "793/793 [==============================] - 0s 89us/sample - loss: 0.4007 - accuracy: 0.8235 - val_loss: 0.5367 - val_accuracy: 0.8090\n",
      "Epoch 37/40\n",
      "793/793 [==============================] - 0s 94us/sample - loss: 0.4012 - accuracy: 0.8222 - val_loss: 0.5434 - val_accuracy: 0.7640\n",
      "Epoch 38/40\n",
      "793/793 [==============================] - 0s 85us/sample - loss: 0.4004 - accuracy: 0.8235 - val_loss: 0.5396 - val_accuracy: 0.7978\n",
      "Epoch 39/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.3983 - accuracy: 0.8285 - val_loss: 0.5391 - val_accuracy: 0.7978\n",
      "Epoch 40/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.4002 - accuracy: 0.8260 - val_loss: 0.5372 - val_accuracy: 0.7753\n",
      "Porcentagem de Acerto 51.02%\n",
      "Porcentagem de Acerto 0.0%\n",
      "Train on 793 samples, validate on 89 samples\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "793/793 [==============================] - 0s 609us/sample - loss: 0.6075 - accuracy: 0.7881 - val_loss: 0.5888 - val_accuracy: 0.7640\n",
      "Epoch 2/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.4996 - accuracy: 0.8033 - val_loss: 0.5485 - val_accuracy: 0.6966\n",
      "Epoch 3/40\n",
      "793/793 [==============================] - 0s 94us/sample - loss: 0.4507 - accuracy: 0.7970 - val_loss: 0.5413 - val_accuracy: 0.7191\n",
      "Epoch 4/40\n",
      "793/793 [==============================] - 0s 81us/sample - loss: 0.4371 - accuracy: 0.7982 - val_loss: 0.5431 - val_accuracy: 0.6966\n",
      "Epoch 5/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4368 - accuracy: 0.7831 - val_loss: 0.5503 - val_accuracy: 0.7079\n",
      "Epoch 6/40\n",
      "793/793 [==============================] - 0s 87us/sample - loss: 0.4316 - accuracy: 0.8020 - val_loss: 0.5340 - val_accuracy: 0.7528\n",
      "Epoch 7/40\n",
      "793/793 [==============================] - 0s 81us/sample - loss: 0.4240 - accuracy: 0.8121 - val_loss: 0.5368 - val_accuracy: 0.7865\n",
      "Epoch 8/40\n",
      "793/793 [==============================] - 0s 84us/sample - loss: 0.4206 - accuracy: 0.8020 - val_loss: 0.5355 - val_accuracy: 0.7640\n",
      "Epoch 9/40\n",
      "793/793 [==============================] - 0s 89us/sample - loss: 0.4182 - accuracy: 0.8108 - val_loss: 0.5328 - val_accuracy: 0.7640\n",
      "Epoch 10/40\n",
      "793/793 [==============================] - 0s 98us/sample - loss: 0.4170 - accuracy: 0.8058 - val_loss: 0.5345 - val_accuracy: 0.7865\n",
      "Epoch 11/40\n",
      "793/793 [==============================] - 0s 81us/sample - loss: 0.4170 - accuracy: 0.8020 - val_loss: 0.5360 - val_accuracy: 0.7865\n",
      "Epoch 12/40\n",
      "793/793 [==============================] - 0s 88us/sample - loss: 0.4178 - accuracy: 0.8045 - val_loss: 0.5412 - val_accuracy: 0.7640\n",
      "Epoch 13/40\n",
      "793/793 [==============================] - 0s 79us/sample - loss: 0.4122 - accuracy: 0.8121 - val_loss: 0.5374 - val_accuracy: 0.7865\n",
      "Epoch 14/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4128 - accuracy: 0.8096 - val_loss: 0.5384 - val_accuracy: 0.7753\n",
      "Epoch 15/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.4108 - accuracy: 0.8184 - val_loss: 0.5366 - val_accuracy: 0.7753\n",
      "Epoch 16/40\n",
      "793/793 [==============================] - 0s 85us/sample - loss: 0.4104 - accuracy: 0.8108 - val_loss: 0.5396 - val_accuracy: 0.7753\n",
      "Epoch 17/40\n",
      "793/793 [==============================] - 0s 83us/sample - loss: 0.4100 - accuracy: 0.8121 - val_loss: 0.5349 - val_accuracy: 0.7640\n",
      "Epoch 18/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4076 - accuracy: 0.8209 - val_loss: 0.5365 - val_accuracy: 0.7865\n",
      "Epoch 19/40\n",
      "793/793 [==============================] - 0s 88us/sample - loss: 0.4065 - accuracy: 0.8146 - val_loss: 0.5372 - val_accuracy: 0.7865\n",
      "Epoch 20/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.4070 - accuracy: 0.8209 - val_loss: 0.5419 - val_accuracy: 0.7978\n",
      "Epoch 21/40\n",
      "793/793 [==============================] - 0s 80us/sample - loss: 0.4063 - accuracy: 0.8260 - val_loss: 0.5349 - val_accuracy: 0.7865\n",
      "Epoch 22/40\n",
      "793/793 [==============================] - 0s 94us/sample - loss: 0.4078 - accuracy: 0.8184 - val_loss: 0.5374 - val_accuracy: 0.7978\n",
      "Epoch 23/40\n",
      "793/793 [==============================] - 0s 86us/sample - loss: 0.4068 - accuracy: 0.8146 - val_loss: 0.5495 - val_accuracy: 0.7865\n",
      "Epoch 24/40\n",
      "793/793 [==============================] - 0s 94us/sample - loss: 0.4049 - accuracy: 0.8222 - val_loss: 0.5363 - val_accuracy: 0.7865\n",
      "Epoch 25/40\n",
      "793/793 [==============================] - 0s 98us/sample - loss: 0.4035 - accuracy: 0.8247 - val_loss: 0.5350 - val_accuracy: 0.7865\n",
      "Epoch 26/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.4044 - accuracy: 0.8285 - val_loss: 0.5410 - val_accuracy: 0.7865\n",
      "Epoch 27/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.4029 - accuracy: 0.8222 - val_loss: 0.5362 - val_accuracy: 0.7865\n",
      "Epoch 28/40\n",
      "793/793 [==============================] - 0s 94us/sample - loss: 0.4040 - accuracy: 0.8146 - val_loss: 0.5344 - val_accuracy: 0.7978\n",
      "Epoch 29/40\n",
      "793/793 [==============================] - 0s 99us/sample - loss: 0.4005 - accuracy: 0.8310 - val_loss: 0.5358 - val_accuracy: 0.7865\n",
      "Epoch 30/40\n",
      "793/793 [==============================] - 0s 87us/sample - loss: 0.4004 - accuracy: 0.8247 - val_loss: 0.5377 - val_accuracy: 0.7865\n",
      "Epoch 31/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.3997 - accuracy: 0.8235 - val_loss: 0.5405 - val_accuracy: 0.7753\n",
      "Epoch 32/40\n",
      "793/793 [==============================] - 0s 94us/sample - loss: 0.3990 - accuracy: 0.8247 - val_loss: 0.5401 - val_accuracy: 0.7753\n",
      "Epoch 33/40\n",
      "793/793 [==============================] - 0s 88us/sample - loss: 0.4017 - accuracy: 0.8298 - val_loss: 0.5367 - val_accuracy: 0.7865\n",
      "Epoch 34/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.3994 - accuracy: 0.8298 - val_loss: 0.5363 - val_accuracy: 0.7978\n",
      "Epoch 35/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.3982 - accuracy: 0.8260 - val_loss: 0.5351 - val_accuracy: 0.7865\n",
      "Epoch 36/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.3982 - accuracy: 0.8285 - val_loss: 0.5371 - val_accuracy: 0.7865\n",
      "Epoch 37/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.4000 - accuracy: 0.8260 - val_loss: 0.5543 - val_accuracy: 0.7753\n",
      "Epoch 38/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.3971 - accuracy: 0.8348 - val_loss: 0.5377 - val_accuracy: 0.7640\n",
      "Epoch 39/40\n",
      "793/793 [==============================] - 0s 84us/sample - loss: 0.4007 - accuracy: 0.8197 - val_loss: 0.5397 - val_accuracy: 0.7865\n",
      "Epoch 40/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.3965 - accuracy: 0.8310 - val_loss: 0.5356 - val_accuracy: 0.7978\n",
      "Porcentagem de Acerto 53.29%\n",
      "Porcentagem de Acerto 0.0%\n",
      "Train on 793 samples, validate on 89 samples\n",
      "Epoch 1/40\n",
      "793/793 [==============================] - 0s 614us/sample - loss: 0.6272 - accuracy: 0.7100 - val_loss: 0.5944 - val_accuracy: 0.7079\n",
      "Epoch 2/40\n",
      "793/793 [==============================] - 0s 87us/sample - loss: 0.5117 - accuracy: 0.7995 - val_loss: 0.5415 - val_accuracy: 0.7191\n",
      "Epoch 3/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4566 - accuracy: 0.8008 - val_loss: 0.5335 - val_accuracy: 0.7416\n",
      "Epoch 4/40\n",
      "793/793 [==============================] - 0s 88us/sample - loss: 0.4418 - accuracy: 0.7982 - val_loss: 0.5328 - val_accuracy: 0.7303\n",
      "Epoch 5/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.4351 - accuracy: 0.7982 - val_loss: 0.5312 - val_accuracy: 0.7753\n",
      "Epoch 6/40\n",
      "793/793 [==============================] - 0s 85us/sample - loss: 0.4297 - accuracy: 0.8020 - val_loss: 0.5319 - val_accuracy: 0.7865\n",
      "Epoch 7/40\n",
      "793/793 [==============================] - 0s 87us/sample - loss: 0.4245 - accuracy: 0.8033 - val_loss: 0.5360 - val_accuracy: 0.7640\n",
      "Epoch 8/40\n",
      "793/793 [==============================] - 0s 88us/sample - loss: 0.4246 - accuracy: 0.7995 - val_loss: 0.5354 - val_accuracy: 0.7865\n",
      "Epoch 9/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.4203 - accuracy: 0.8071 - val_loss: 0.5397 - val_accuracy: 0.7640\n",
      "Epoch 10/40\n",
      "793/793 [==============================] - 0s 87us/sample - loss: 0.4169 - accuracy: 0.8045 - val_loss: 0.5356 - val_accuracy: 0.7640\n",
      "Epoch 11/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4160 - accuracy: 0.8008 - val_loss: 0.5364 - val_accuracy: 0.7753\n",
      "Epoch 12/40\n",
      "793/793 [==============================] - 0s 97us/sample - loss: 0.4186 - accuracy: 0.8020 - val_loss: 0.5401 - val_accuracy: 0.7640\n",
      "Epoch 13/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.4130 - accuracy: 0.8096 - val_loss: 0.5361 - val_accuracy: 0.7640\n",
      "Epoch 14/40\n",
      "793/793 [==============================] - 0s 87us/sample - loss: 0.4113 - accuracy: 0.8121 - val_loss: 0.5408 - val_accuracy: 0.7640\n",
      "Epoch 15/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4107 - accuracy: 0.8121 - val_loss: 0.5390 - val_accuracy: 0.7865\n",
      "Epoch 16/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "793/793 [==============================] - 0s 96us/sample - loss: 0.4128 - accuracy: 0.8146 - val_loss: 0.5406 - val_accuracy: 0.7753\n",
      "Epoch 17/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4092 - accuracy: 0.8134 - val_loss: 0.5403 - val_accuracy: 0.7865\n",
      "Epoch 18/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.4085 - accuracy: 0.8184 - val_loss: 0.5432 - val_accuracy: 0.7865\n",
      "Epoch 19/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.4077 - accuracy: 0.8172 - val_loss: 0.5427 - val_accuracy: 0.7865\n",
      "Epoch 20/40\n",
      "793/793 [==============================] - 0s 81us/sample - loss: 0.4071 - accuracy: 0.8184 - val_loss: 0.5461 - val_accuracy: 0.7978\n",
      "Epoch 21/40\n",
      "793/793 [==============================] - 0s 89us/sample - loss: 0.4122 - accuracy: 0.8146 - val_loss: 0.5481 - val_accuracy: 0.7640\n",
      "Epoch 22/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4109 - accuracy: 0.8134 - val_loss: 0.5431 - val_accuracy: 0.7865\n",
      "Epoch 23/40\n",
      "793/793 [==============================] - 0s 84us/sample - loss: 0.4038 - accuracy: 0.8197 - val_loss: 0.5402 - val_accuracy: 0.7753\n",
      "Epoch 24/40\n",
      "793/793 [==============================] - 0s 88us/sample - loss: 0.4037 - accuracy: 0.8159 - val_loss: 0.5412 - val_accuracy: 0.7865\n",
      "Epoch 25/40\n",
      "793/793 [==============================] - 0s 81us/sample - loss: 0.4043 - accuracy: 0.8209 - val_loss: 0.5411 - val_accuracy: 0.7865\n",
      "Epoch 26/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4030 - accuracy: 0.8184 - val_loss: 0.5369 - val_accuracy: 0.7978\n",
      "Epoch 27/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.4039 - accuracy: 0.8247 - val_loss: 0.5419 - val_accuracy: 0.7865\n",
      "Epoch 28/40\n",
      "793/793 [==============================] - 0s 99us/sample - loss: 0.4035 - accuracy: 0.8222 - val_loss: 0.5386 - val_accuracy: 0.7865\n",
      "Epoch 29/40\n",
      "793/793 [==============================] - 0s 88us/sample - loss: 0.4029 - accuracy: 0.8209 - val_loss: 0.5388 - val_accuracy: 0.7528\n",
      "Epoch 30/40\n",
      "793/793 [==============================] - 0s 98us/sample - loss: 0.4032 - accuracy: 0.8209 - val_loss: 0.5467 - val_accuracy: 0.7865\n",
      "Epoch 31/40\n",
      "793/793 [==============================] - 0s 99us/sample - loss: 0.4016 - accuracy: 0.8222 - val_loss: 0.5406 - val_accuracy: 0.7753\n",
      "Epoch 32/40\n",
      "793/793 [==============================] - 0s 89us/sample - loss: 0.4007 - accuracy: 0.8247 - val_loss: 0.5456 - val_accuracy: 0.7865\n",
      "Epoch 33/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.3996 - accuracy: 0.8247 - val_loss: 0.5401 - val_accuracy: 0.7865\n",
      "Epoch 34/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.4053 - accuracy: 0.8159 - val_loss: 0.5387 - val_accuracy: 0.7978\n",
      "Epoch 35/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4002 - accuracy: 0.8247 - val_loss: 0.5497 - val_accuracy: 0.7865\n",
      "Epoch 36/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.3985 - accuracy: 0.8235 - val_loss: 0.5398 - val_accuracy: 0.7753\n",
      "Epoch 37/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.3992 - accuracy: 0.8197 - val_loss: 0.5430 - val_accuracy: 0.7865\n",
      "Epoch 38/40\n",
      "793/793 [==============================] - 0s 97us/sample - loss: 0.3983 - accuracy: 0.8260 - val_loss: 0.5420 - val_accuracy: 0.7865\n",
      "Epoch 39/40\n",
      "793/793 [==============================] - 0s 82us/sample - loss: 0.3982 - accuracy: 0.8197 - val_loss: 0.5446 - val_accuracy: 0.7753\n",
      "Epoch 40/40\n",
      "793/793 [==============================] - 0s 94us/sample - loss: 0.4002 - accuracy: 0.8235 - val_loss: 0.5440 - val_accuracy: 0.7865\n",
      "Porcentagem de Acerto 52.72%\n",
      "Porcentagem de Acerto 0.0%\n",
      "Train on 793 samples, validate on 89 samples\n",
      "Epoch 1/40\n",
      "793/793 [==============================] - 0s 598us/sample - loss: 0.5862 - accuracy: 0.7465 - val_loss: 0.5689 - val_accuracy: 0.7079\n",
      "Epoch 2/40\n",
      "793/793 [==============================] - 0s 77us/sample - loss: 0.4809 - accuracy: 0.7869 - val_loss: 0.5439 - val_accuracy: 0.7303\n",
      "Epoch 3/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4488 - accuracy: 0.8008 - val_loss: 0.5440 - val_accuracy: 0.6966\n",
      "Epoch 4/40\n",
      "793/793 [==============================] - 0s 96us/sample - loss: 0.4394 - accuracy: 0.7995 - val_loss: 0.5465 - val_accuracy: 0.7079\n",
      "Epoch 5/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4341 - accuracy: 0.8020 - val_loss: 0.5469 - val_accuracy: 0.7191\n",
      "Epoch 6/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.4254 - accuracy: 0.8020 - val_loss: 0.5392 - val_accuracy: 0.7640\n",
      "Epoch 7/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.4224 - accuracy: 0.8071 - val_loss: 0.5387 - val_accuracy: 0.7640\n",
      "Epoch 8/40\n",
      "793/793 [==============================] - 0s 103us/sample - loss: 0.4198 - accuracy: 0.8033 - val_loss: 0.5447 - val_accuracy: 0.7303\n",
      "Epoch 9/40\n",
      "793/793 [==============================] - 0s 81us/sample - loss: 0.4168 - accuracy: 0.8045 - val_loss: 0.5429 - val_accuracy: 0.7528\n",
      "Epoch 10/40\n",
      "793/793 [==============================] - 0s 98us/sample - loss: 0.4144 - accuracy: 0.8020 - val_loss: 0.5401 - val_accuracy: 0.7753\n",
      "Epoch 11/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.4118 - accuracy: 0.8071 - val_loss: 0.5365 - val_accuracy: 0.7753\n",
      "Epoch 12/40\n",
      "793/793 [==============================] - 0s 96us/sample - loss: 0.4101 - accuracy: 0.8058 - val_loss: 0.5435 - val_accuracy: 0.7640\n",
      "Epoch 13/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4087 - accuracy: 0.8058 - val_loss: 0.5407 - val_accuracy: 0.7753\n",
      "Epoch 14/40\n",
      "793/793 [==============================] - 0s 94us/sample - loss: 0.4080 - accuracy: 0.8121 - val_loss: 0.5364 - val_accuracy: 0.7978\n",
      "Epoch 15/40\n",
      "793/793 [==============================] - 0s 111us/sample - loss: 0.4091 - accuracy: 0.8121 - val_loss: 0.5419 - val_accuracy: 0.7865\n",
      "Epoch 16/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.4060 - accuracy: 0.8146 - val_loss: 0.5406 - val_accuracy: 0.7865\n",
      "Epoch 17/40\n",
      "793/793 [==============================] - 0s 82us/sample - loss: 0.4058 - accuracy: 0.8184 - val_loss: 0.5419 - val_accuracy: 0.7865\n",
      "Epoch 18/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4046 - accuracy: 0.8222 - val_loss: 0.5421 - val_accuracy: 0.7753\n",
      "Epoch 19/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4047 - accuracy: 0.8209 - val_loss: 0.5338 - val_accuracy: 0.7753\n",
      "Epoch 20/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.4091 - accuracy: 0.8146 - val_loss: 0.5580 - val_accuracy: 0.7191\n",
      "Epoch 21/40\n",
      "793/793 [==============================] - 0s 94us/sample - loss: 0.4078 - accuracy: 0.8235 - val_loss: 0.5522 - val_accuracy: 0.7865\n",
      "Epoch 22/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.4049 - accuracy: 0.8197 - val_loss: 0.5404 - val_accuracy: 0.7865\n",
      "Epoch 23/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4020 - accuracy: 0.8285 - val_loss: 0.5344 - val_accuracy: 0.7865\n",
      "Epoch 24/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.4096 - accuracy: 0.8146 - val_loss: 0.5362 - val_accuracy: 0.7640\n",
      "Epoch 25/40\n",
      "793/793 [==============================] - 0s 88us/sample - loss: 0.4050 - accuracy: 0.8272 - val_loss: 0.5413 - val_accuracy: 0.7865\n",
      "Epoch 26/40\n",
      "793/793 [==============================] - 0s 96us/sample - loss: 0.4023 - accuracy: 0.8335 - val_loss: 0.5559 - val_accuracy: 0.7753\n",
      "Epoch 27/40\n",
      "793/793 [==============================] - 0s 88us/sample - loss: 0.4089 - accuracy: 0.8159 - val_loss: 0.5352 - val_accuracy: 0.7865\n",
      "Epoch 28/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.3985 - accuracy: 0.8298 - val_loss: 0.5335 - val_accuracy: 0.7753\n",
      "Epoch 29/40\n",
      "793/793 [==============================] - 0s 89us/sample - loss: 0.3987 - accuracy: 0.8310 - val_loss: 0.5397 - val_accuracy: 0.7865\n",
      "Epoch 30/40\n",
      "793/793 [==============================] - 0s 89us/sample - loss: 0.3973 - accuracy: 0.8285 - val_loss: 0.5373 - val_accuracy: 0.7865\n",
      "Epoch 31/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "793/793 [==============================] - 0s 98us/sample - loss: 0.3966 - accuracy: 0.8272 - val_loss: 0.5399 - val_accuracy: 0.7865\n",
      "Epoch 32/40\n",
      "793/793 [==============================] - 0s 83us/sample - loss: 0.3964 - accuracy: 0.8272 - val_loss: 0.5320 - val_accuracy: 0.7865\n",
      "Epoch 33/40\n",
      "793/793 [==============================] - 0s 79us/sample - loss: 0.3971 - accuracy: 0.8285 - val_loss: 0.5414 - val_accuracy: 0.7865\n",
      "Epoch 34/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.3978 - accuracy: 0.8285 - val_loss: 0.5434 - val_accuracy: 0.7978\n",
      "Epoch 35/40\n",
      "793/793 [==============================] - 0s 82us/sample - loss: 0.3981 - accuracy: 0.8247 - val_loss: 0.5474 - val_accuracy: 0.7865\n",
      "Epoch 36/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.3973 - accuracy: 0.8285 - val_loss: 0.5370 - val_accuracy: 0.7978\n",
      "Epoch 37/40\n",
      "793/793 [==============================] - 0s 94us/sample - loss: 0.3954 - accuracy: 0.8260 - val_loss: 0.5452 - val_accuracy: 0.7865\n",
      "Epoch 38/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.3965 - accuracy: 0.8159 - val_loss: 0.5394 - val_accuracy: 0.7865\n",
      "Epoch 39/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.3945 - accuracy: 0.8222 - val_loss: 0.5449 - val_accuracy: 0.7978\n",
      "Epoch 40/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.3939 - accuracy: 0.8247 - val_loss: 0.5352 - val_accuracy: 0.7865\n",
      "Porcentagem de Acerto 51.59%\n",
      "Porcentagem de Acerto 0.0%\n",
      "Train on 793 samples, validate on 89 samples\n",
      "Epoch 1/40\n",
      "793/793 [==============================] - 1s 727us/sample - loss: 0.6317 - accuracy: 0.6822 - val_loss: 0.6038 - val_accuracy: 0.6966\n",
      "Epoch 2/40\n",
      "793/793 [==============================] - 0s 87us/sample - loss: 0.5270 - accuracy: 0.7907 - val_loss: 0.5538 - val_accuracy: 0.7416\n",
      "Epoch 3/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.4671 - accuracy: 0.7945 - val_loss: 0.5514 - val_accuracy: 0.6966\n",
      "Epoch 4/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4486 - accuracy: 0.8008 - val_loss: 0.5466 - val_accuracy: 0.7416\n",
      "Epoch 5/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.4433 - accuracy: 0.7982 - val_loss: 0.5464 - val_accuracy: 0.7079\n",
      "Epoch 6/40\n",
      "793/793 [==============================] - 0s 98us/sample - loss: 0.4366 - accuracy: 0.8033 - val_loss: 0.5483 - val_accuracy: 0.7079\n",
      "Epoch 7/40\n",
      "793/793 [==============================] - 0s 88us/sample - loss: 0.4339 - accuracy: 0.7982 - val_loss: 0.5349 - val_accuracy: 0.7640\n",
      "Epoch 8/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4244 - accuracy: 0.8083 - val_loss: 0.5381 - val_accuracy: 0.7753\n",
      "Epoch 9/40\n",
      "793/793 [==============================] - 0s 101us/sample - loss: 0.4210 - accuracy: 0.8045 - val_loss: 0.5429 - val_accuracy: 0.7640\n",
      "Epoch 10/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.4184 - accuracy: 0.8058 - val_loss: 0.5361 - val_accuracy: 0.7528\n",
      "Epoch 11/40\n",
      "793/793 [==============================] - 0s 87us/sample - loss: 0.4205 - accuracy: 0.8108 - val_loss: 0.5357 - val_accuracy: 0.7865\n",
      "Epoch 12/40\n",
      "793/793 [==============================] - 0s 82us/sample - loss: 0.4154 - accuracy: 0.8045 - val_loss: 0.5352 - val_accuracy: 0.7640\n",
      "Epoch 13/40\n",
      "793/793 [==============================] - 0s 101us/sample - loss: 0.4131 - accuracy: 0.8108 - val_loss: 0.5381 - val_accuracy: 0.7753\n",
      "Epoch 14/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.4137 - accuracy: 0.8096 - val_loss: 0.5398 - val_accuracy: 0.7640\n",
      "Epoch 15/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.4111 - accuracy: 0.8083 - val_loss: 0.5379 - val_accuracy: 0.7753\n",
      "Epoch 16/40\n",
      "793/793 [==============================] - 0s 94us/sample - loss: 0.4102 - accuracy: 0.8033 - val_loss: 0.5458 - val_accuracy: 0.7640\n",
      "Epoch 17/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4139 - accuracy: 0.8108 - val_loss: 0.5368 - val_accuracy: 0.7865\n",
      "Epoch 18/40\n",
      "793/793 [==============================] - 0s 101us/sample - loss: 0.4122 - accuracy: 0.8159 - val_loss: 0.5374 - val_accuracy: 0.7640\n",
      "Epoch 19/40\n",
      "793/793 [==============================] - 0s 94us/sample - loss: 0.4104 - accuracy: 0.8033 - val_loss: 0.5369 - val_accuracy: 0.7978\n",
      "Epoch 20/40\n",
      "793/793 [==============================] - 0s 94us/sample - loss: 0.4072 - accuracy: 0.8247 - val_loss: 0.5358 - val_accuracy: 0.7865\n",
      "Epoch 21/40\n",
      "793/793 [==============================] - 0s 98us/sample - loss: 0.4069 - accuracy: 0.8247 - val_loss: 0.5546 - val_accuracy: 0.7640\n",
      "Epoch 22/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4100 - accuracy: 0.8159 - val_loss: 0.5374 - val_accuracy: 0.7865\n",
      "Epoch 23/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.4050 - accuracy: 0.8159 - val_loss: 0.5367 - val_accuracy: 0.7865\n",
      "Epoch 24/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.4047 - accuracy: 0.8235 - val_loss: 0.5402 - val_accuracy: 0.7753\n",
      "Epoch 25/40\n",
      "793/793 [==============================] - 0s 100us/sample - loss: 0.4037 - accuracy: 0.8209 - val_loss: 0.5385 - val_accuracy: 0.7978\n",
      "Epoch 26/40\n",
      "793/793 [==============================] - 0s 98us/sample - loss: 0.4046 - accuracy: 0.8222 - val_loss: 0.5413 - val_accuracy: 0.7978\n",
      "Epoch 27/40\n",
      "793/793 [==============================] - 0s 97us/sample - loss: 0.4025 - accuracy: 0.8235 - val_loss: 0.5394 - val_accuracy: 0.7978\n",
      "Epoch 28/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4027 - accuracy: 0.8272 - val_loss: 0.5334 - val_accuracy: 0.7865\n",
      "Epoch 29/40\n",
      "793/793 [==============================] - 0s 97us/sample - loss: 0.4007 - accuracy: 0.8184 - val_loss: 0.5408 - val_accuracy: 0.7865\n",
      "Epoch 30/40\n",
      "793/793 [==============================] - 0s 84us/sample - loss: 0.3999 - accuracy: 0.8222 - val_loss: 0.5371 - val_accuracy: 0.7865\n",
      "Epoch 31/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.4023 - accuracy: 0.8310 - val_loss: 0.5342 - val_accuracy: 0.7865\n",
      "Epoch 32/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.4039 - accuracy: 0.8184 - val_loss: 0.5387 - val_accuracy: 0.7865\n",
      "Epoch 33/40\n",
      "793/793 [==============================] - 0s 88us/sample - loss: 0.4007 - accuracy: 0.8209 - val_loss: 0.5363 - val_accuracy: 0.7865\n",
      "Epoch 34/40\n",
      "793/793 [==============================] - 0s 98us/sample - loss: 0.3983 - accuracy: 0.8361 - val_loss: 0.5371 - val_accuracy: 0.7865\n",
      "Epoch 35/40\n",
      "793/793 [==============================] - 0s 89us/sample - loss: 0.4003 - accuracy: 0.8121 - val_loss: 0.5361 - val_accuracy: 0.7865\n",
      "Epoch 36/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.3996 - accuracy: 0.8197 - val_loss: 0.5432 - val_accuracy: 0.7978\n",
      "Epoch 37/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.3983 - accuracy: 0.8373 - val_loss: 0.5368 - val_accuracy: 0.7865\n",
      "Epoch 38/40\n",
      "793/793 [==============================] - 0s 89us/sample - loss: 0.3982 - accuracy: 0.8247 - val_loss: 0.5370 - val_accuracy: 0.7978\n",
      "Epoch 39/40\n",
      "793/793 [==============================] - 0s 96us/sample - loss: 0.3966 - accuracy: 0.8285 - val_loss: 0.5314 - val_accuracy: 0.7978\n",
      "Epoch 40/40\n",
      "793/793 [==============================] - 0s 99us/sample - loss: 0.4004 - accuracy: 0.8222 - val_loss: 0.5329 - val_accuracy: 0.8090\n",
      "Porcentagem de Acerto 51.25%\n",
      "Porcentagem de Acerto 0.0%\n",
      "Train on 793 samples, validate on 89 samples\n",
      "Epoch 1/40\n",
      "793/793 [==============================] - 0s 601us/sample - loss: 0.6321 - accuracy: 0.6469 - val_loss: 0.6054 - val_accuracy: 0.6742\n",
      "Epoch 2/40\n",
      "793/793 [==============================] - 0s 94us/sample - loss: 0.5354 - accuracy: 0.7806 - val_loss: 0.5590 - val_accuracy: 0.7191\n",
      "Epoch 3/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4803 - accuracy: 0.8020 - val_loss: 0.5541 - val_accuracy: 0.6966\n",
      "Epoch 4/40\n",
      "793/793 [==============================] - 0s 104us/sample - loss: 0.4591 - accuracy: 0.7982 - val_loss: 0.5472 - val_accuracy: 0.6966\n",
      "Epoch 5/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.4472 - accuracy: 0.8058 - val_loss: 0.5468 - val_accuracy: 0.7528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4383 - accuracy: 0.7995 - val_loss: 0.5386 - val_accuracy: 0.7303\n",
      "Epoch 7/40\n",
      "793/793 [==============================] - 0s 97us/sample - loss: 0.4290 - accuracy: 0.8045 - val_loss: 0.5390 - val_accuracy: 0.7865\n",
      "Epoch 8/40\n",
      "793/793 [==============================] - 0s 96us/sample - loss: 0.4238 - accuracy: 0.8033 - val_loss: 0.5400 - val_accuracy: 0.7865\n",
      "Epoch 9/40\n",
      "793/793 [==============================] - 0s 96us/sample - loss: 0.4240 - accuracy: 0.8045 - val_loss: 0.5356 - val_accuracy: 0.7640\n",
      "Epoch 10/40\n",
      "793/793 [==============================] - 0s 87us/sample - loss: 0.4201 - accuracy: 0.8096 - val_loss: 0.5401 - val_accuracy: 0.7978\n",
      "Epoch 11/40\n",
      "793/793 [==============================] - 0s 84us/sample - loss: 0.4150 - accuracy: 0.8083 - val_loss: 0.5377 - val_accuracy: 0.7865\n",
      "Epoch 12/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.4128 - accuracy: 0.8159 - val_loss: 0.5420 - val_accuracy: 0.7640\n",
      "Epoch 13/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.4154 - accuracy: 0.8108 - val_loss: 0.5416 - val_accuracy: 0.7865\n",
      "Epoch 14/40\n",
      "793/793 [==============================] - 0s 78us/sample - loss: 0.4183 - accuracy: 0.8108 - val_loss: 0.5325 - val_accuracy: 0.7865\n",
      "Epoch 15/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4127 - accuracy: 0.8159 - val_loss: 0.5377 - val_accuracy: 0.7865\n",
      "Epoch 16/40\n",
      "793/793 [==============================] - 0s 96us/sample - loss: 0.4123 - accuracy: 0.8134 - val_loss: 0.5344 - val_accuracy: 0.7865\n",
      "Epoch 17/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4079 - accuracy: 0.8172 - val_loss: 0.5414 - val_accuracy: 0.7753\n",
      "Epoch 18/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4057 - accuracy: 0.8146 - val_loss: 0.5397 - val_accuracy: 0.7978\n",
      "Epoch 19/40\n",
      "793/793 [==============================] - 0s 105us/sample - loss: 0.4060 - accuracy: 0.8209 - val_loss: 0.5410 - val_accuracy: 0.7865\n",
      "Epoch 20/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4045 - accuracy: 0.8235 - val_loss: 0.5346 - val_accuracy: 0.8090\n",
      "Epoch 21/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4040 - accuracy: 0.8159 - val_loss: 0.5373 - val_accuracy: 0.7978\n",
      "Epoch 22/40\n",
      "793/793 [==============================] - 0s 86us/sample - loss: 0.4042 - accuracy: 0.8197 - val_loss: 0.5503 - val_accuracy: 0.7865\n",
      "Epoch 23/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.4046 - accuracy: 0.8260 - val_loss: 0.5316 - val_accuracy: 0.7753\n",
      "Epoch 24/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4087 - accuracy: 0.8146 - val_loss: 0.5463 - val_accuracy: 0.7528\n",
      "Epoch 25/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4115 - accuracy: 0.8146 - val_loss: 0.5340 - val_accuracy: 0.7865\n",
      "Epoch 26/40\n",
      "793/793 [==============================] - 0s 94us/sample - loss: 0.4021 - accuracy: 0.8235 - val_loss: 0.5332 - val_accuracy: 0.8090\n",
      "Epoch 27/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4009 - accuracy: 0.8298 - val_loss: 0.5357 - val_accuracy: 0.7865\n",
      "Epoch 28/40\n",
      "793/793 [==============================] - 0s 88us/sample - loss: 0.4002 - accuracy: 0.8260 - val_loss: 0.5540 - val_accuracy: 0.7865\n",
      "Epoch 29/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4020 - accuracy: 0.8235 - val_loss: 0.5386 - val_accuracy: 0.7528\n",
      "Epoch 30/40\n",
      "793/793 [==============================] - 0s 100us/sample - loss: 0.3999 - accuracy: 0.8235 - val_loss: 0.5469 - val_accuracy: 0.7753\n",
      "Epoch 31/40\n",
      "793/793 [==============================] - 0s 96us/sample - loss: 0.4000 - accuracy: 0.8298 - val_loss: 0.5314 - val_accuracy: 0.8090\n",
      "Epoch 32/40\n",
      "793/793 [==============================] - 0s 98us/sample - loss: 0.3972 - accuracy: 0.8298 - val_loss: 0.5445 - val_accuracy: 0.7753\n",
      "Epoch 33/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.4017 - accuracy: 0.8159 - val_loss: 0.5364 - val_accuracy: 0.7640\n",
      "Epoch 34/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.3966 - accuracy: 0.8184 - val_loss: 0.5359 - val_accuracy: 0.7865\n",
      "Epoch 35/40\n",
      "793/793 [==============================] - 0s 88us/sample - loss: 0.4020 - accuracy: 0.8310 - val_loss: 0.5371 - val_accuracy: 0.7978\n",
      "Epoch 36/40\n",
      "793/793 [==============================] - 0s 82us/sample - loss: 0.3985 - accuracy: 0.8323 - val_loss: 0.5365 - val_accuracy: 0.7865\n",
      "Epoch 37/40\n",
      "793/793 [==============================] - 0s 87us/sample - loss: 0.3981 - accuracy: 0.8197 - val_loss: 0.5375 - val_accuracy: 0.8090\n",
      "Epoch 38/40\n",
      "793/793 [==============================] - 0s 82us/sample - loss: 0.3968 - accuracy: 0.8298 - val_loss: 0.5334 - val_accuracy: 0.7978\n",
      "Epoch 39/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4010 - accuracy: 0.8209 - val_loss: 0.5335 - val_accuracy: 0.7753\n",
      "Epoch 40/40\n",
      "793/793 [==============================] - 0s 97us/sample - loss: 0.3985 - accuracy: 0.8285 - val_loss: 0.5415 - val_accuracy: 0.8090\n",
      "Porcentagem de Acerto 51.7%\n",
      "Porcentagem de Acerto 0.0%\n",
      "Train on 793 samples, validate on 89 samples\n",
      "Epoch 1/40\n",
      "793/793 [==============================] - 0s 594us/sample - loss: 0.6341 - accuracy: 0.7289 - val_loss: 0.6096 - val_accuracy: 0.6966\n",
      "Epoch 2/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.5190 - accuracy: 0.7945 - val_loss: 0.5490 - val_accuracy: 0.6966\n",
      "Epoch 3/40\n",
      "793/793 [==============================] - 0s 100us/sample - loss: 0.4542 - accuracy: 0.7995 - val_loss: 0.5385 - val_accuracy: 0.7079\n",
      "Epoch 4/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.4405 - accuracy: 0.8020 - val_loss: 0.5362 - val_accuracy: 0.7079\n",
      "Epoch 5/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.4327 - accuracy: 0.8045 - val_loss: 0.5321 - val_accuracy: 0.7528\n",
      "Epoch 6/40\n",
      "793/793 [==============================] - 0s 104us/sample - loss: 0.4291 - accuracy: 0.8045 - val_loss: 0.5347 - val_accuracy: 0.7528\n",
      "Epoch 7/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.4245 - accuracy: 0.8033 - val_loss: 0.5339 - val_accuracy: 0.7528\n",
      "Epoch 8/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4227 - accuracy: 0.8008 - val_loss: 0.5432 - val_accuracy: 0.7303\n",
      "Epoch 9/40\n",
      "793/793 [==============================] - 0s 87us/sample - loss: 0.4225 - accuracy: 0.7995 - val_loss: 0.5385 - val_accuracy: 0.7640\n",
      "Epoch 10/40\n",
      "793/793 [==============================] - 0s 100us/sample - loss: 0.4212 - accuracy: 0.8146 - val_loss: 0.5403 - val_accuracy: 0.7865\n",
      "Epoch 11/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.4153 - accuracy: 0.8134 - val_loss: 0.5403 - val_accuracy: 0.7753\n",
      "Epoch 12/40\n",
      "793/793 [==============================] - 0s 98us/sample - loss: 0.4171 - accuracy: 0.8096 - val_loss: 0.5396 - val_accuracy: 0.7640\n",
      "Epoch 13/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.4159 - accuracy: 0.8071 - val_loss: 0.5416 - val_accuracy: 0.7640\n",
      "Epoch 14/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.4145 - accuracy: 0.8020 - val_loss: 0.5462 - val_accuracy: 0.7640\n",
      "Epoch 15/40\n",
      "793/793 [==============================] - 0s 103us/sample - loss: 0.4132 - accuracy: 0.8083 - val_loss: 0.5417 - val_accuracy: 0.7753\n",
      "Epoch 16/40\n",
      "793/793 [==============================] - 0s 101us/sample - loss: 0.4121 - accuracy: 0.8134 - val_loss: 0.5426 - val_accuracy: 0.7753\n",
      "Epoch 17/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.4100 - accuracy: 0.8071 - val_loss: 0.5388 - val_accuracy: 0.7978\n",
      "Epoch 18/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.4114 - accuracy: 0.8146 - val_loss: 0.5455 - val_accuracy: 0.7640\n",
      "Epoch 19/40\n",
      "793/793 [==============================] - 0s 86us/sample - loss: 0.4100 - accuracy: 0.8184 - val_loss: 0.5474 - val_accuracy: 0.7865\n",
      "Epoch 20/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4101 - accuracy: 0.8146 - val_loss: 0.5522 - val_accuracy: 0.7640\n",
      "Epoch 21/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4112 - accuracy: 0.8184 - val_loss: 0.5418 - val_accuracy: 0.7865\n",
      "Epoch 22/40\n",
      "793/793 [==============================] - 0s 94us/sample - loss: 0.4102 - accuracy: 0.8134 - val_loss: 0.5422 - val_accuracy: 0.7865\n",
      "Epoch 23/40\n",
      "793/793 [==============================] - 0s 94us/sample - loss: 0.4072 - accuracy: 0.8121 - val_loss: 0.5391 - val_accuracy: 0.7865\n",
      "Epoch 24/40\n",
      "793/793 [==============================] - 0s 102us/sample - loss: 0.4061 - accuracy: 0.8184 - val_loss: 0.5446 - val_accuracy: 0.7978\n",
      "Epoch 25/40\n",
      "793/793 [==============================] - 0s 97us/sample - loss: 0.4108 - accuracy: 0.8209 - val_loss: 0.5567 - val_accuracy: 0.7753\n",
      "Epoch 26/40\n",
      "793/793 [==============================] - 0s 94us/sample - loss: 0.4160 - accuracy: 0.8172 - val_loss: 0.5432 - val_accuracy: 0.7753\n",
      "Epoch 27/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4058 - accuracy: 0.8197 - val_loss: 0.5419 - val_accuracy: 0.7865\n",
      "Epoch 28/40\n",
      "793/793 [==============================] - 0s 89us/sample - loss: 0.4051 - accuracy: 0.8209 - val_loss: 0.5433 - val_accuracy: 0.7865\n",
      "Epoch 29/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4111 - accuracy: 0.8096 - val_loss: 0.5460 - val_accuracy: 0.7865\n",
      "Epoch 30/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4025 - accuracy: 0.8197 - val_loss: 0.5415 - val_accuracy: 0.7753\n",
      "Epoch 31/40\n",
      "793/793 [==============================] - 0s 98us/sample - loss: 0.4053 - accuracy: 0.8096 - val_loss: 0.5472 - val_accuracy: 0.7753\n",
      "Epoch 32/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4011 - accuracy: 0.8247 - val_loss: 0.5423 - val_accuracy: 0.7865\n",
      "Epoch 33/40\n",
      "793/793 [==============================] - 0s 94us/sample - loss: 0.4013 - accuracy: 0.8272 - val_loss: 0.5432 - val_accuracy: 0.8090\n",
      "Epoch 34/40\n",
      "793/793 [==============================] - 0s 100us/sample - loss: 0.4004 - accuracy: 0.8209 - val_loss: 0.5474 - val_accuracy: 0.7865\n",
      "Epoch 35/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.4002 - accuracy: 0.8159 - val_loss: 0.5427 - val_accuracy: 0.7865\n",
      "Epoch 36/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.3986 - accuracy: 0.8247 - val_loss: 0.5474 - val_accuracy: 0.7978\n",
      "Epoch 37/40\n",
      "793/793 [==============================] - 0s 107us/sample - loss: 0.3978 - accuracy: 0.8260 - val_loss: 0.5419 - val_accuracy: 0.7865\n",
      "Epoch 38/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.3979 - accuracy: 0.8209 - val_loss: 0.5456 - val_accuracy: 0.7865\n",
      "Epoch 39/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.3978 - accuracy: 0.8298 - val_loss: 0.5397 - val_accuracy: 0.7865\n",
      "Epoch 40/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.3963 - accuracy: 0.8285 - val_loss: 0.5441 - val_accuracy: 0.7865\n",
      "Porcentagem de Acerto 52.72%\n",
      "Porcentagem de Acerto 0.0%\n",
      "Train on 793 samples, validate on 89 samples\n",
      "Epoch 1/40\n",
      "793/793 [==============================] - 0s 596us/sample - loss: 0.5939 - accuracy: 0.7894 - val_loss: 0.5727 - val_accuracy: 0.6966\n",
      "Epoch 2/40\n",
      "793/793 [==============================] - 0s 89us/sample - loss: 0.4710 - accuracy: 0.7907 - val_loss: 0.5476 - val_accuracy: 0.6966\n",
      "Epoch 3/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.4449 - accuracy: 0.7957 - val_loss: 0.5438 - val_accuracy: 0.6966\n",
      "Epoch 4/40\n",
      "793/793 [==============================] - 0s 84us/sample - loss: 0.4410 - accuracy: 0.7894 - val_loss: 0.5341 - val_accuracy: 0.7528\n",
      "Epoch 5/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.4309 - accuracy: 0.8008 - val_loss: 0.5411 - val_accuracy: 0.7640\n",
      "Epoch 6/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.4268 - accuracy: 0.8121 - val_loss: 0.5444 - val_accuracy: 0.7303\n",
      "Epoch 7/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.4252 - accuracy: 0.8096 - val_loss: 0.5359 - val_accuracy: 0.7640\n",
      "Epoch 8/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4221 - accuracy: 0.8020 - val_loss: 0.5442 - val_accuracy: 0.7303\n",
      "Epoch 9/40\n",
      "793/793 [==============================] - 0s 100us/sample - loss: 0.4165 - accuracy: 0.8033 - val_loss: 0.5411 - val_accuracy: 0.7640\n",
      "Epoch 10/40\n",
      "793/793 [==============================] - 0s 94us/sample - loss: 0.4240 - accuracy: 0.7957 - val_loss: 0.5449 - val_accuracy: 0.7753\n",
      "Epoch 11/40\n",
      "793/793 [==============================] - 0s 96us/sample - loss: 0.4302 - accuracy: 0.7982 - val_loss: 0.5328 - val_accuracy: 0.7978\n",
      "Epoch 12/40\n",
      "793/793 [==============================] - 0s 88us/sample - loss: 0.4134 - accuracy: 0.8008 - val_loss: 0.5406 - val_accuracy: 0.7753\n",
      "Epoch 13/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4128 - accuracy: 0.8096 - val_loss: 0.5424 - val_accuracy: 0.7865\n",
      "Epoch 14/40\n",
      "793/793 [==============================] - 0s 97us/sample - loss: 0.4124 - accuracy: 0.8071 - val_loss: 0.5431 - val_accuracy: 0.7865\n",
      "Epoch 15/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.4102 - accuracy: 0.8159 - val_loss: 0.5343 - val_accuracy: 0.7865\n",
      "Epoch 16/40\n",
      "793/793 [==============================] - 0s 98us/sample - loss: 0.4073 - accuracy: 0.8159 - val_loss: 0.5421 - val_accuracy: 0.7865\n",
      "Epoch 17/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4077 - accuracy: 0.8121 - val_loss: 0.5400 - val_accuracy: 0.7865\n",
      "Epoch 18/40\n",
      "793/793 [==============================] - 0s 102us/sample - loss: 0.4065 - accuracy: 0.8197 - val_loss: 0.5417 - val_accuracy: 0.7865\n",
      "Epoch 19/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4094 - accuracy: 0.8146 - val_loss: 0.5417 - val_accuracy: 0.7865\n",
      "Epoch 20/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4050 - accuracy: 0.8197 - val_loss: 0.5381 - val_accuracy: 0.7865\n",
      "Epoch 21/40\n",
      "793/793 [==============================] - 0s 98us/sample - loss: 0.4044 - accuracy: 0.8184 - val_loss: 0.5421 - val_accuracy: 0.7865\n",
      "Epoch 22/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.4047 - accuracy: 0.8172 - val_loss: 0.5411 - val_accuracy: 0.8090\n",
      "Epoch 23/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.4061 - accuracy: 0.8310 - val_loss: 0.5474 - val_accuracy: 0.7753\n",
      "Epoch 24/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4046 - accuracy: 0.8209 - val_loss: 0.5455 - val_accuracy: 0.7978\n",
      "Epoch 25/40\n",
      "793/793 [==============================] - 0s 96us/sample - loss: 0.4053 - accuracy: 0.8159 - val_loss: 0.5346 - val_accuracy: 0.7865\n",
      "Epoch 26/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.4046 - accuracy: 0.8134 - val_loss: 0.5371 - val_accuracy: 0.7865\n",
      "Epoch 27/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4047 - accuracy: 0.8197 - val_loss: 0.5406 - val_accuracy: 0.7978\n",
      "Epoch 28/40\n",
      "793/793 [==============================] - 0s 101us/sample - loss: 0.3990 - accuracy: 0.8348 - val_loss: 0.5398 - val_accuracy: 0.8090\n",
      "Epoch 29/40\n",
      "793/793 [==============================] - 0s 98us/sample - loss: 0.4049 - accuracy: 0.8235 - val_loss: 0.5430 - val_accuracy: 0.7865\n",
      "Epoch 30/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.4026 - accuracy: 0.8172 - val_loss: 0.5409 - val_accuracy: 0.7978\n",
      "Epoch 31/40\n",
      "793/793 [==============================] - 0s 102us/sample - loss: 0.3997 - accuracy: 0.8260 - val_loss: 0.5419 - val_accuracy: 0.7978\n",
      "Epoch 32/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.3996 - accuracy: 0.8285 - val_loss: 0.5452 - val_accuracy: 0.7865\n",
      "Epoch 33/40\n",
      "793/793 [==============================] - 0s 89us/sample - loss: 0.3976 - accuracy: 0.8235 - val_loss: 0.5348 - val_accuracy: 0.7978\n",
      "Epoch 34/40\n",
      "793/793 [==============================] - 0s 86us/sample - loss: 0.3971 - accuracy: 0.8323 - val_loss: 0.5397 - val_accuracy: 0.7865\n",
      "Epoch 35/40\n",
      "793/793 [==============================] - 0s 99us/sample - loss: 0.3969 - accuracy: 0.8272 - val_loss: 0.5463 - val_accuracy: 0.7865\n",
      "Epoch 36/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "793/793 [==============================] - 0s 86us/sample - loss: 0.3963 - accuracy: 0.8235 - val_loss: 0.5412 - val_accuracy: 0.8090\n",
      "Epoch 37/40\n",
      "793/793 [==============================] - 0s 103us/sample - loss: 0.3947 - accuracy: 0.8247 - val_loss: 0.5381 - val_accuracy: 0.7640\n",
      "Epoch 38/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.3985 - accuracy: 0.8323 - val_loss: 0.5745 - val_accuracy: 0.7416\n",
      "Epoch 39/40\n",
      "793/793 [==============================] - 0s 96us/sample - loss: 0.4065 - accuracy: 0.8209 - val_loss: 0.5431 - val_accuracy: 0.7978\n",
      "Epoch 40/40\n",
      "793/793 [==============================] - 0s 98us/sample - loss: 0.3928 - accuracy: 0.8373 - val_loss: 0.5430 - val_accuracy: 0.8090\n",
      "Porcentagem de Acerto 53.17%\n",
      "Porcentagem de Acerto 0.0%\n",
      "Train on 793 samples, validate on 89 samples\n",
      "Epoch 1/40\n",
      "793/793 [==============================] - 0s 612us/sample - loss: 0.6049 - accuracy: 0.7629 - val_loss: 0.5758 - val_accuracy: 0.7191\n",
      "Epoch 2/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4797 - accuracy: 0.7932 - val_loss: 0.5524 - val_accuracy: 0.6966\n",
      "Epoch 3/40\n",
      "793/793 [==============================] - 0s 98us/sample - loss: 0.4492 - accuracy: 0.7970 - val_loss: 0.5524 - val_accuracy: 0.6966\n",
      "Epoch 4/40\n",
      "793/793 [==============================] - 0s 88us/sample - loss: 0.4382 - accuracy: 0.7982 - val_loss: 0.5336 - val_accuracy: 0.7528\n",
      "Epoch 5/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.4301 - accuracy: 0.8033 - val_loss: 0.5418 - val_accuracy: 0.7303\n",
      "Epoch 6/40\n",
      "793/793 [==============================] - 0s 98us/sample - loss: 0.4256 - accuracy: 0.8045 - val_loss: 0.5452 - val_accuracy: 0.7528\n",
      "Epoch 7/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4225 - accuracy: 0.8033 - val_loss: 0.5376 - val_accuracy: 0.7528\n",
      "Epoch 8/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4187 - accuracy: 0.7995 - val_loss: 0.5398 - val_accuracy: 0.7753\n",
      "Epoch 9/40\n",
      "793/793 [==============================] - 0s 94us/sample - loss: 0.4180 - accuracy: 0.8071 - val_loss: 0.5492 - val_accuracy: 0.7865\n",
      "Epoch 10/40\n",
      "793/793 [==============================] - 0s 94us/sample - loss: 0.4142 - accuracy: 0.8033 - val_loss: 0.5433 - val_accuracy: 0.7753\n",
      "Epoch 11/40\n",
      "793/793 [==============================] - 0s 101us/sample - loss: 0.4148 - accuracy: 0.8134 - val_loss: 0.5348 - val_accuracy: 0.7753\n",
      "Epoch 12/40\n",
      "793/793 [==============================] - 0s 102us/sample - loss: 0.4123 - accuracy: 0.8058 - val_loss: 0.5410 - val_accuracy: 0.7865\n",
      "Epoch 13/40\n",
      "793/793 [==============================] - 0s 98us/sample - loss: 0.4095 - accuracy: 0.8134 - val_loss: 0.5354 - val_accuracy: 0.7865\n",
      "Epoch 14/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.4093 - accuracy: 0.8096 - val_loss: 0.5377 - val_accuracy: 0.7978\n",
      "Epoch 15/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4115 - accuracy: 0.8096 - val_loss: 0.5449 - val_accuracy: 0.7753\n",
      "Epoch 16/40\n",
      "793/793 [==============================] - 0s 97us/sample - loss: 0.4081 - accuracy: 0.8071 - val_loss: 0.5414 - val_accuracy: 0.7978\n",
      "Epoch 17/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.4087 - accuracy: 0.8083 - val_loss: 0.5471 - val_accuracy: 0.7978\n",
      "Epoch 18/40\n",
      "793/793 [==============================] - 0s 104us/sample - loss: 0.4074 - accuracy: 0.8222 - val_loss: 0.5349 - val_accuracy: 0.7865\n",
      "Epoch 19/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.4085 - accuracy: 0.8209 - val_loss: 0.5366 - val_accuracy: 0.7865\n",
      "Epoch 20/40\n",
      "793/793 [==============================] - 0s 100us/sample - loss: 0.4056 - accuracy: 0.8058 - val_loss: 0.5417 - val_accuracy: 0.7865\n",
      "Epoch 21/40\n",
      "793/793 [==============================] - 0s 100us/sample - loss: 0.4120 - accuracy: 0.8134 - val_loss: 0.5408 - val_accuracy: 0.7865\n",
      "Epoch 22/40\n",
      "793/793 [==============================] - 0s 98us/sample - loss: 0.4096 - accuracy: 0.8247 - val_loss: 0.5525 - val_accuracy: 0.7753\n",
      "Epoch 23/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4042 - accuracy: 0.8159 - val_loss: 0.5340 - val_accuracy: 0.7978\n",
      "Epoch 24/40\n",
      "793/793 [==============================] - 0s 94us/sample - loss: 0.4084 - accuracy: 0.8172 - val_loss: 0.5441 - val_accuracy: 0.7865\n",
      "Epoch 25/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4031 - accuracy: 0.8159 - val_loss: 0.5395 - val_accuracy: 0.7753\n",
      "Epoch 26/40\n",
      "793/793 [==============================] - 0s 99us/sample - loss: 0.4037 - accuracy: 0.8260 - val_loss: 0.5345 - val_accuracy: 0.8090\n",
      "Epoch 27/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.4015 - accuracy: 0.8247 - val_loss: 0.5365 - val_accuracy: 0.7640\n",
      "Epoch 28/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4030 - accuracy: 0.8235 - val_loss: 0.5393 - val_accuracy: 0.7978\n",
      "Epoch 29/40\n",
      "793/793 [==============================] - 0s 96us/sample - loss: 0.4003 - accuracy: 0.8235 - val_loss: 0.5354 - val_accuracy: 0.7865\n",
      "Epoch 30/40\n",
      "793/793 [==============================] - 0s 102us/sample - loss: 0.3984 - accuracy: 0.8260 - val_loss: 0.5340 - val_accuracy: 0.7640\n",
      "Epoch 31/40\n",
      "793/793 [==============================] - 0s 89us/sample - loss: 0.4001 - accuracy: 0.8235 - val_loss: 0.5400 - val_accuracy: 0.7753\n",
      "Epoch 32/40\n",
      "793/793 [==============================] - 0s 97us/sample - loss: 0.4008 - accuracy: 0.8209 - val_loss: 0.5364 - val_accuracy: 0.7978\n",
      "Epoch 33/40\n",
      "793/793 [==============================] - 0s 96us/sample - loss: 0.3974 - accuracy: 0.8298 - val_loss: 0.5446 - val_accuracy: 0.7865\n",
      "Epoch 34/40\n",
      "793/793 [==============================] - 0s 99us/sample - loss: 0.3978 - accuracy: 0.8310 - val_loss: 0.5334 - val_accuracy: 0.7753\n",
      "Epoch 35/40\n",
      "793/793 [==============================] - 0s 97us/sample - loss: 0.3985 - accuracy: 0.8134 - val_loss: 0.5434 - val_accuracy: 0.7753\n",
      "Epoch 36/40\n",
      "793/793 [==============================] - 0s 99us/sample - loss: 0.3968 - accuracy: 0.8222 - val_loss: 0.5350 - val_accuracy: 0.8090\n",
      "Epoch 37/40\n",
      "793/793 [==============================] - 0s 97us/sample - loss: 0.3977 - accuracy: 0.8335 - val_loss: 0.5402 - val_accuracy: 0.7753\n",
      "Epoch 38/40\n",
      "793/793 [==============================] - 0s 98us/sample - loss: 0.3970 - accuracy: 0.8285 - val_loss: 0.5346 - val_accuracy: 0.7640\n",
      "Epoch 39/40\n",
      "793/793 [==============================] - 0s 99us/sample - loss: 0.3941 - accuracy: 0.8310 - val_loss: 0.5418 - val_accuracy: 0.7753\n",
      "Epoch 40/40\n",
      "793/793 [==============================] - 0s 97us/sample - loss: 0.3940 - accuracy: 0.8310 - val_loss: 0.5355 - val_accuracy: 0.7528\n",
      "Porcentagem de Acerto 50.57%\n",
      "Porcentagem de Acerto 0.0%\n",
      "Train on 793 samples, validate on 89 samples\n",
      "Epoch 1/40\n",
      "793/793 [==============================] - 0s 596us/sample - loss: 0.6034 - accuracy: 0.7566 - val_loss: 0.5762 - val_accuracy: 0.6966\n",
      "Epoch 2/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.4695 - accuracy: 0.7982 - val_loss: 0.5410 - val_accuracy: 0.6966\n",
      "Epoch 3/40\n",
      "793/793 [==============================] - 0s 98us/sample - loss: 0.4423 - accuracy: 0.7982 - val_loss: 0.5445 - val_accuracy: 0.7640\n",
      "Epoch 4/40\n",
      "793/793 [==============================] - 0s 102us/sample - loss: 0.4401 - accuracy: 0.8058 - val_loss: 0.5384 - val_accuracy: 0.7528\n",
      "Epoch 5/40\n",
      "793/793 [==============================] - 0s 97us/sample - loss: 0.4309 - accuracy: 0.8020 - val_loss: 0.5343 - val_accuracy: 0.7528\n",
      "Epoch 6/40\n",
      "793/793 [==============================] - 0s 97us/sample - loss: 0.4285 - accuracy: 0.8008 - val_loss: 0.5331 - val_accuracy: 0.7753\n",
      "Epoch 7/40\n",
      "793/793 [==============================] - 0s 98us/sample - loss: 0.4279 - accuracy: 0.8045 - val_loss: 0.5365 - val_accuracy: 0.7865\n",
      "Epoch 8/40\n",
      "793/793 [==============================] - 0s 96us/sample - loss: 0.4215 - accuracy: 0.8096 - val_loss: 0.5335 - val_accuracy: 0.7753\n",
      "Epoch 9/40\n",
      "793/793 [==============================] - 0s 102us/sample - loss: 0.4202 - accuracy: 0.8184 - val_loss: 0.5381 - val_accuracy: 0.7640\n",
      "Epoch 10/40\n",
      "793/793 [==============================] - 0s 98us/sample - loss: 0.4174 - accuracy: 0.8159 - val_loss: 0.5402 - val_accuracy: 0.7753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4161 - accuracy: 0.8134 - val_loss: 0.5370 - val_accuracy: 0.7640\n",
      "Epoch 12/40\n",
      "793/793 [==============================] - 0s 97us/sample - loss: 0.4154 - accuracy: 0.8096 - val_loss: 0.5422 - val_accuracy: 0.7753\n",
      "Epoch 13/40\n",
      "793/793 [==============================] - 0s 88us/sample - loss: 0.4175 - accuracy: 0.7982 - val_loss: 0.5545 - val_accuracy: 0.7865\n",
      "Epoch 14/40\n",
      "793/793 [==============================] - 0s 96us/sample - loss: 0.4139 - accuracy: 0.8134 - val_loss: 0.5682 - val_accuracy: 0.6742\n",
      "Epoch 15/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4180 - accuracy: 0.7995 - val_loss: 0.5368 - val_accuracy: 0.7640\n",
      "Epoch 16/40\n",
      "793/793 [==============================] - 0s 102us/sample - loss: 0.4130 - accuracy: 0.8096 - val_loss: 0.5453 - val_accuracy: 0.7640\n",
      "Epoch 17/40\n",
      "793/793 [==============================] - 0s 99us/sample - loss: 0.4113 - accuracy: 0.8146 - val_loss: 0.5382 - val_accuracy: 0.7865\n",
      "Epoch 18/40\n",
      "793/793 [==============================] - 0s 97us/sample - loss: 0.4118 - accuracy: 0.8058 - val_loss: 0.5462 - val_accuracy: 0.7753\n",
      "Epoch 19/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4094 - accuracy: 0.8134 - val_loss: 0.5438 - val_accuracy: 0.7753\n",
      "Epoch 20/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.4084 - accuracy: 0.8197 - val_loss: 0.5391 - val_accuracy: 0.7865\n",
      "Epoch 21/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4126 - accuracy: 0.8146 - val_loss: 0.5395 - val_accuracy: 0.7753\n",
      "Epoch 22/40\n",
      "793/793 [==============================] - 0s 94us/sample - loss: 0.4106 - accuracy: 0.8020 - val_loss: 0.5448 - val_accuracy: 0.7865\n",
      "Epoch 23/40\n",
      "793/793 [==============================] - 0s 81us/sample - loss: 0.4063 - accuracy: 0.8172 - val_loss: 0.5430 - val_accuracy: 0.7753\n",
      "Epoch 24/40\n",
      "793/793 [==============================] - 0s 96us/sample - loss: 0.4068 - accuracy: 0.8197 - val_loss: 0.5478 - val_accuracy: 0.7753\n",
      "Epoch 25/40\n",
      "793/793 [==============================] - 0s 101us/sample - loss: 0.4044 - accuracy: 0.8159 - val_loss: 0.5487 - val_accuracy: 0.7528\n",
      "Epoch 26/40\n",
      "793/793 [==============================] - 0s 97us/sample - loss: 0.4059 - accuracy: 0.8260 - val_loss: 0.5407 - val_accuracy: 0.7865\n",
      "Epoch 27/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.4044 - accuracy: 0.8197 - val_loss: 0.5458 - val_accuracy: 0.7753\n",
      "Epoch 28/40\n",
      "793/793 [==============================] - 0s 96us/sample - loss: 0.4067 - accuracy: 0.8209 - val_loss: 0.5641 - val_accuracy: 0.7416\n",
      "Epoch 29/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4095 - accuracy: 0.8146 - val_loss: 0.5422 - val_accuracy: 0.7978\n",
      "Epoch 30/40\n",
      "793/793 [==============================] - 0s 94us/sample - loss: 0.4029 - accuracy: 0.8222 - val_loss: 0.5427 - val_accuracy: 0.7753\n",
      "Epoch 31/40\n",
      "793/793 [==============================] - 0s 94us/sample - loss: 0.4041 - accuracy: 0.8184 - val_loss: 0.5431 - val_accuracy: 0.7865\n",
      "Epoch 32/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.4105 - accuracy: 0.8184 - val_loss: 0.5441 - val_accuracy: 0.7753\n",
      "Epoch 33/40\n",
      "793/793 [==============================] - 0s 101us/sample - loss: 0.4017 - accuracy: 0.8209 - val_loss: 0.5457 - val_accuracy: 0.7753\n",
      "Epoch 34/40\n",
      "793/793 [==============================] - 0s 96us/sample - loss: 0.4016 - accuracy: 0.8209 - val_loss: 0.5463 - val_accuracy: 0.7865\n",
      "Epoch 35/40\n",
      "793/793 [==============================] - 0s 108us/sample - loss: 0.3992 - accuracy: 0.8235 - val_loss: 0.5393 - val_accuracy: 0.7978\n",
      "Epoch 36/40\n",
      "793/793 [==============================] - 0s 87us/sample - loss: 0.4020 - accuracy: 0.8197 - val_loss: 0.5420 - val_accuracy: 0.7978\n",
      "Epoch 37/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4005 - accuracy: 0.8235 - val_loss: 0.5364 - val_accuracy: 0.7640\n",
      "Epoch 38/40\n",
      "793/793 [==============================] - 0s 106us/sample - loss: 0.3981 - accuracy: 0.8310 - val_loss: 0.5441 - val_accuracy: 0.7978\n",
      "Epoch 39/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.3984 - accuracy: 0.8285 - val_loss: 0.5453 - val_accuracy: 0.7416\n",
      "Epoch 40/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.3960 - accuracy: 0.8323 - val_loss: 0.5440 - val_accuracy: 0.7978\n",
      "Porcentagem de Acerto 52.72%\n",
      "Porcentagem de Acerto 0.0%\n",
      "Train on 793 samples, validate on 89 samples\n",
      "Epoch 1/40\n",
      "793/793 [==============================] - 0s 602us/sample - loss: 0.6051 - accuracy: 0.7579 - val_loss: 0.5731 - val_accuracy: 0.7079\n",
      "Epoch 2/40\n",
      "793/793 [==============================] - 0s 96us/sample - loss: 0.4705 - accuracy: 0.7957 - val_loss: 0.5463 - val_accuracy: 0.6966\n",
      "Epoch 3/40\n",
      "793/793 [==============================] - 0s 100us/sample - loss: 0.4421 - accuracy: 0.8008 - val_loss: 0.5439 - val_accuracy: 0.7191\n",
      "Epoch 4/40\n",
      "793/793 [==============================] - 0s 100us/sample - loss: 0.4316 - accuracy: 0.8020 - val_loss: 0.5375 - val_accuracy: 0.7303\n",
      "Epoch 5/40\n",
      "793/793 [==============================] - 0s 100us/sample - loss: 0.4257 - accuracy: 0.8071 - val_loss: 0.5383 - val_accuracy: 0.7640\n",
      "Epoch 6/40\n",
      "793/793 [==============================] - 0s 97us/sample - loss: 0.4241 - accuracy: 0.8083 - val_loss: 0.5325 - val_accuracy: 0.7753\n",
      "Epoch 7/40\n",
      "793/793 [==============================] - 0s 97us/sample - loss: 0.4202 - accuracy: 0.8096 - val_loss: 0.5425 - val_accuracy: 0.7528\n",
      "Epoch 8/40\n",
      "793/793 [==============================] - 0s 109us/sample - loss: 0.4179 - accuracy: 0.7995 - val_loss: 0.5467 - val_accuracy: 0.7640\n",
      "Epoch 9/40\n",
      "793/793 [==============================] - 0s 97us/sample - loss: 0.4169 - accuracy: 0.7970 - val_loss: 0.5453 - val_accuracy: 0.7640\n",
      "Epoch 10/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.4176 - accuracy: 0.7970 - val_loss: 0.5458 - val_accuracy: 0.7640\n",
      "Epoch 11/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4128 - accuracy: 0.8083 - val_loss: 0.5422 - val_accuracy: 0.7753\n",
      "Epoch 12/40\n",
      "793/793 [==============================] - 0s 102us/sample - loss: 0.4131 - accuracy: 0.8058 - val_loss: 0.5514 - val_accuracy: 0.7640\n",
      "Epoch 13/40\n",
      "793/793 [==============================] - 0s 99us/sample - loss: 0.4107 - accuracy: 0.8096 - val_loss: 0.5574 - val_accuracy: 0.7640\n",
      "Epoch 14/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.4131 - accuracy: 0.8045 - val_loss: 0.5384 - val_accuracy: 0.7865\n",
      "Epoch 15/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4090 - accuracy: 0.8222 - val_loss: 0.5474 - val_accuracy: 0.7753\n",
      "Epoch 16/40\n",
      "793/793 [==============================] - 0s 103us/sample - loss: 0.4077 - accuracy: 0.8260 - val_loss: 0.5456 - val_accuracy: 0.7978\n",
      "Epoch 17/40\n",
      "793/793 [==============================] - 0s 107us/sample - loss: 0.4085 - accuracy: 0.8146 - val_loss: 0.5468 - val_accuracy: 0.7416\n",
      "Epoch 18/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.4093 - accuracy: 0.8134 - val_loss: 0.5378 - val_accuracy: 0.7978\n",
      "Epoch 19/40\n",
      "793/793 [==============================] - 0s 97us/sample - loss: 0.4041 - accuracy: 0.8121 - val_loss: 0.5447 - val_accuracy: 0.7753\n",
      "Epoch 20/40\n",
      "793/793 [==============================] - 0s 104us/sample - loss: 0.4065 - accuracy: 0.8235 - val_loss: 0.5372 - val_accuracy: 0.8090\n",
      "Epoch 21/40\n",
      "793/793 [==============================] - 0s 101us/sample - loss: 0.4028 - accuracy: 0.8260 - val_loss: 0.5417 - val_accuracy: 0.7978\n",
      "Epoch 22/40\n",
      "793/793 [==============================] - 0s 102us/sample - loss: 0.4006 - accuracy: 0.8247 - val_loss: 0.5424 - val_accuracy: 0.7865\n",
      "Epoch 23/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.4015 - accuracy: 0.8272 - val_loss: 0.5466 - val_accuracy: 0.7528\n",
      "Epoch 24/40\n",
      "793/793 [==============================] - 0s 101us/sample - loss: 0.4017 - accuracy: 0.8209 - val_loss: 0.5382 - val_accuracy: 0.7978\n",
      "Epoch 25/40\n",
      "793/793 [==============================] - 0s 105us/sample - loss: 0.3999 - accuracy: 0.8272 - val_loss: 0.5376 - val_accuracy: 0.7865\n",
      "Epoch 26/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "793/793 [==============================] - 0s 103us/sample - loss: 0.4006 - accuracy: 0.8323 - val_loss: 0.5411 - val_accuracy: 0.7753\n",
      "Epoch 27/40\n",
      "793/793 [==============================] - 0s 96us/sample - loss: 0.4003 - accuracy: 0.8272 - val_loss: 0.5376 - val_accuracy: 0.7865\n",
      "Epoch 28/40\n",
      "793/793 [==============================] - 0s 103us/sample - loss: 0.3957 - accuracy: 0.8197 - val_loss: 0.5510 - val_accuracy: 0.7753\n",
      "Epoch 29/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4012 - accuracy: 0.8222 - val_loss: 0.5375 - val_accuracy: 0.7978\n",
      "Epoch 30/40\n",
      "793/793 [==============================] - 0s 101us/sample - loss: 0.3977 - accuracy: 0.8272 - val_loss: 0.5376 - val_accuracy: 0.7865\n",
      "Epoch 31/40\n",
      "793/793 [==============================] - 0s 102us/sample - loss: 0.3957 - accuracy: 0.8235 - val_loss: 0.5346 - val_accuracy: 0.7978\n",
      "Epoch 32/40\n",
      "793/793 [==============================] - 0s 98us/sample - loss: 0.3945 - accuracy: 0.8209 - val_loss: 0.5443 - val_accuracy: 0.7978\n",
      "Epoch 33/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.3965 - accuracy: 0.8209 - val_loss: 0.5396 - val_accuracy: 0.7865\n",
      "Epoch 34/40\n",
      "793/793 [==============================] - 0s 102us/sample - loss: 0.3952 - accuracy: 0.8197 - val_loss: 0.5394 - val_accuracy: 0.7978\n",
      "Epoch 35/40\n",
      "793/793 [==============================] - 0s 99us/sample - loss: 0.3945 - accuracy: 0.8272 - val_loss: 0.5435 - val_accuracy: 0.7978\n",
      "Epoch 36/40\n",
      "793/793 [==============================] - 0s 100us/sample - loss: 0.3948 - accuracy: 0.8121 - val_loss: 0.5314 - val_accuracy: 0.7640\n",
      "Epoch 37/40\n",
      "793/793 [==============================] - 0s 114us/sample - loss: 0.3954 - accuracy: 0.8272 - val_loss: 0.5555 - val_accuracy: 0.7416\n",
      "Epoch 38/40\n",
      "793/793 [==============================] - 0s 103us/sample - loss: 0.3904 - accuracy: 0.8235 - val_loss: 0.5398 - val_accuracy: 0.7978\n",
      "Epoch 39/40\n",
      "793/793 [==============================] - 0s 100us/sample - loss: 0.3912 - accuracy: 0.8335 - val_loss: 0.5387 - val_accuracy: 0.7978\n",
      "Epoch 40/40\n",
      "793/793 [==============================] - 0s 101us/sample - loss: 0.3971 - accuracy: 0.8235 - val_loss: 0.5367 - val_accuracy: 0.8090\n",
      "Porcentagem de Acerto 52.27%\n",
      "Porcentagem de Acerto 0.0%\n",
      "Train on 793 samples, validate on 89 samples\n",
      "Epoch 1/40\n",
      "793/793 [==============================] - 0s 593us/sample - loss: 0.5913 - accuracy: 0.7692 - val_loss: 0.5659 - val_accuracy: 0.7303\n",
      "Epoch 2/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4762 - accuracy: 0.7894 - val_loss: 0.5468 - val_accuracy: 0.7303\n",
      "Epoch 3/40\n",
      "793/793 [==============================] - 0s 106us/sample - loss: 0.4470 - accuracy: 0.8033 - val_loss: 0.5491 - val_accuracy: 0.6966\n",
      "Epoch 4/40\n",
      "793/793 [==============================] - 0s 99us/sample - loss: 0.4453 - accuracy: 0.7957 - val_loss: 0.5382 - val_accuracy: 0.7079\n",
      "Epoch 5/40\n",
      "793/793 [==============================] - 0s 102us/sample - loss: 0.4341 - accuracy: 0.8045 - val_loss: 0.5337 - val_accuracy: 0.7753\n",
      "Epoch 6/40\n",
      "793/793 [==============================] - 0s 103us/sample - loss: 0.4259 - accuracy: 0.8033 - val_loss: 0.5321 - val_accuracy: 0.7865\n",
      "Epoch 7/40\n",
      "793/793 [==============================] - 0s 108us/sample - loss: 0.4221 - accuracy: 0.8020 - val_loss: 0.5340 - val_accuracy: 0.7640\n",
      "Epoch 8/40\n",
      "793/793 [==============================] - 0s 102us/sample - loss: 0.4187 - accuracy: 0.8172 - val_loss: 0.5370 - val_accuracy: 0.7753\n",
      "Epoch 9/40\n",
      "793/793 [==============================] - 0s 103us/sample - loss: 0.4172 - accuracy: 0.8159 - val_loss: 0.5393 - val_accuracy: 0.7753\n",
      "Epoch 10/40\n",
      "793/793 [==============================] - 0s 103us/sample - loss: 0.4157 - accuracy: 0.8096 - val_loss: 0.5370 - val_accuracy: 0.7753\n",
      "Epoch 11/40\n",
      "793/793 [==============================] - 0s 108us/sample - loss: 0.4160 - accuracy: 0.8020 - val_loss: 0.5371 - val_accuracy: 0.7753\n",
      "Epoch 12/40\n",
      "793/793 [==============================] - 0s 100us/sample - loss: 0.4128 - accuracy: 0.8083 - val_loss: 0.5430 - val_accuracy: 0.7640\n",
      "Epoch 13/40\n",
      "793/793 [==============================] - 0s 108us/sample - loss: 0.4149 - accuracy: 0.8071 - val_loss: 0.5370 - val_accuracy: 0.7865\n",
      "Epoch 14/40\n",
      "793/793 [==============================] - 0s 103us/sample - loss: 0.4124 - accuracy: 0.8108 - val_loss: 0.5360 - val_accuracy: 0.8090\n",
      "Epoch 15/40\n",
      "793/793 [==============================] - 0s 100us/sample - loss: 0.4139 - accuracy: 0.8033 - val_loss: 0.5333 - val_accuracy: 0.7753\n",
      "Epoch 16/40\n",
      "793/793 [==============================] - 0s 99us/sample - loss: 0.4074 - accuracy: 0.8222 - val_loss: 0.5551 - val_accuracy: 0.7865\n",
      "Epoch 17/40\n",
      "793/793 [==============================] - 0s 107us/sample - loss: 0.4073 - accuracy: 0.8146 - val_loss: 0.5405 - val_accuracy: 0.7640\n",
      "Epoch 18/40\n",
      "793/793 [==============================] - 0s 98us/sample - loss: 0.4079 - accuracy: 0.8146 - val_loss: 0.5381 - val_accuracy: 0.7865\n",
      "Epoch 19/40\n",
      "793/793 [==============================] - 0s 98us/sample - loss: 0.4082 - accuracy: 0.8197 - val_loss: 0.5465 - val_accuracy: 0.7416\n",
      "Epoch 20/40\n",
      "793/793 [==============================] - 0s 110us/sample - loss: 0.4071 - accuracy: 0.8146 - val_loss: 0.5396 - val_accuracy: 0.8090\n",
      "Epoch 21/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4024 - accuracy: 0.8260 - val_loss: 0.5417 - val_accuracy: 0.7978\n",
      "Epoch 22/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4016 - accuracy: 0.8260 - val_loss: 0.5427 - val_accuracy: 0.7753\n",
      "Epoch 23/40\n",
      "793/793 [==============================] - 0s 111us/sample - loss: 0.4024 - accuracy: 0.8260 - val_loss: 0.5417 - val_accuracy: 0.7865\n",
      "Epoch 24/40\n",
      "793/793 [==============================] - 0s 99us/sample - loss: 0.4032 - accuracy: 0.8272 - val_loss: 0.5338 - val_accuracy: 0.7640\n",
      "Epoch 25/40\n",
      "793/793 [==============================] - 0s 102us/sample - loss: 0.3984 - accuracy: 0.8310 - val_loss: 0.5455 - val_accuracy: 0.7753\n",
      "Epoch 26/40\n",
      "793/793 [==============================] - 0s 106us/sample - loss: 0.3977 - accuracy: 0.8235 - val_loss: 0.5389 - val_accuracy: 0.7865\n",
      "Epoch 27/40\n",
      "793/793 [==============================] - 0s 99us/sample - loss: 0.3988 - accuracy: 0.8298 - val_loss: 0.5373 - val_accuracy: 0.8090\n",
      "Epoch 28/40\n",
      "793/793 [==============================] - 0s 101us/sample - loss: 0.3958 - accuracy: 0.8172 - val_loss: 0.5433 - val_accuracy: 0.7865\n",
      "Epoch 29/40\n",
      "793/793 [==============================] - 0s 97us/sample - loss: 0.3964 - accuracy: 0.8285 - val_loss: 0.5384 - val_accuracy: 0.7865\n",
      "Epoch 30/40\n",
      "793/793 [==============================] - 0s 104us/sample - loss: 0.4013 - accuracy: 0.8184 - val_loss: 0.5421 - val_accuracy: 0.8090\n",
      "Epoch 31/40\n",
      "793/793 [==============================] - 0s 98us/sample - loss: 0.3986 - accuracy: 0.8260 - val_loss: 0.5388 - val_accuracy: 0.7865\n",
      "Epoch 32/40\n",
      "793/793 [==============================] - 0s 105us/sample - loss: 0.3987 - accuracy: 0.8260 - val_loss: 0.5401 - val_accuracy: 0.7978\n",
      "Epoch 33/40\n",
      "793/793 [==============================] - 0s 100us/sample - loss: 0.3960 - accuracy: 0.8235 - val_loss: 0.5365 - val_accuracy: 0.7978\n",
      "Epoch 34/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.3933 - accuracy: 0.8310 - val_loss: 0.5429 - val_accuracy: 0.7865\n",
      "Epoch 35/40\n",
      "793/793 [==============================] - 0s 105us/sample - loss: 0.3935 - accuracy: 0.8285 - val_loss: 0.5365 - val_accuracy: 0.8090\n",
      "Epoch 36/40\n",
      "793/793 [==============================] - 0s 100us/sample - loss: 0.3930 - accuracy: 0.8335 - val_loss: 0.5442 - val_accuracy: 0.8090\n",
      "Epoch 37/40\n",
      "793/793 [==============================] - 0s 98us/sample - loss: 0.3912 - accuracy: 0.8272 - val_loss: 0.5429 - val_accuracy: 0.7978\n",
      "Epoch 38/40\n",
      "793/793 [==============================] - 0s 110us/sample - loss: 0.3918 - accuracy: 0.8335 - val_loss: 0.5556 - val_accuracy: 0.7528\n",
      "Epoch 39/40\n",
      "793/793 [==============================] - 0s 103us/sample - loss: 0.3926 - accuracy: 0.8272 - val_loss: 0.5395 - val_accuracy: 0.7978\n",
      "Epoch 40/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.3888 - accuracy: 0.8222 - val_loss: 0.5492 - val_accuracy: 0.7528\n",
      "Porcentagem de Acerto 51.13%\n",
      "Porcentagem de Acerto 0.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 793 samples, validate on 89 samples\n",
      "Epoch 1/40\n",
      "793/793 [==============================] - 0s 600us/sample - loss: 0.6127 - accuracy: 0.7251 - val_loss: 0.5726 - val_accuracy: 0.7528\n",
      "Epoch 2/40\n",
      "793/793 [==============================] - 0s 94us/sample - loss: 0.4787 - accuracy: 0.7932 - val_loss: 0.5409 - val_accuracy: 0.6966\n",
      "Epoch 3/40\n",
      "793/793 [==============================] - 0s 98us/sample - loss: 0.4420 - accuracy: 0.7982 - val_loss: 0.5389 - val_accuracy: 0.7191\n",
      "Epoch 4/40\n",
      "793/793 [==============================] - 0s 97us/sample - loss: 0.4367 - accuracy: 0.7995 - val_loss: 0.5364 - val_accuracy: 0.7528\n",
      "Epoch 5/40\n",
      "793/793 [==============================] - 0s 99us/sample - loss: 0.4295 - accuracy: 0.8020 - val_loss: 0.5373 - val_accuracy: 0.7528\n",
      "Epoch 6/40\n",
      "793/793 [==============================] - 0s 96us/sample - loss: 0.4277 - accuracy: 0.7995 - val_loss: 0.5336 - val_accuracy: 0.7753\n",
      "Epoch 7/40\n",
      "793/793 [==============================] - 0s 96us/sample - loss: 0.4298 - accuracy: 0.8071 - val_loss: 0.5425 - val_accuracy: 0.7640\n",
      "Epoch 8/40\n",
      "793/793 [==============================] - 0s 99us/sample - loss: 0.4205 - accuracy: 0.8045 - val_loss: 0.5407 - val_accuracy: 0.7753\n",
      "Epoch 9/40\n",
      "793/793 [==============================] - 0s 106us/sample - loss: 0.4163 - accuracy: 0.8058 - val_loss: 0.5389 - val_accuracy: 0.7865\n",
      "Epoch 10/40\n",
      "793/793 [==============================] - 0s 94us/sample - loss: 0.4166 - accuracy: 0.8058 - val_loss: 0.5519 - val_accuracy: 0.7640\n",
      "Epoch 11/40\n",
      "793/793 [==============================] - 0s 99us/sample - loss: 0.4139 - accuracy: 0.8083 - val_loss: 0.5433 - val_accuracy: 0.7640\n",
      "Epoch 12/40\n",
      "793/793 [==============================] - 0s 97us/sample - loss: 0.4097 - accuracy: 0.8083 - val_loss: 0.5494 - val_accuracy: 0.7640\n",
      "Epoch 13/40\n",
      "793/793 [==============================] - 0s 104us/sample - loss: 0.4128 - accuracy: 0.8146 - val_loss: 0.5418 - val_accuracy: 0.7978\n",
      "Epoch 14/40\n",
      "793/793 [==============================] - 0s 98us/sample - loss: 0.4148 - accuracy: 0.8083 - val_loss: 0.5491 - val_accuracy: 0.7753\n",
      "Epoch 15/40\n",
      "793/793 [==============================] - 0s 98us/sample - loss: 0.4095 - accuracy: 0.8235 - val_loss: 0.5363 - val_accuracy: 0.7865\n",
      "Epoch 16/40\n",
      "793/793 [==============================] - 0s 104us/sample - loss: 0.4099 - accuracy: 0.8108 - val_loss: 0.5429 - val_accuracy: 0.7865\n",
      "Epoch 17/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.4078 - accuracy: 0.8197 - val_loss: 0.5400 - val_accuracy: 0.7978\n",
      "Epoch 18/40\n",
      "793/793 [==============================] - 0s 101us/sample - loss: 0.4069 - accuracy: 0.8146 - val_loss: 0.5449 - val_accuracy: 0.7978\n",
      "Epoch 19/40\n",
      "793/793 [==============================] - 0s 96us/sample - loss: 0.4079 - accuracy: 0.8172 - val_loss: 0.5427 - val_accuracy: 0.7865\n",
      "Epoch 20/40\n",
      "793/793 [==============================] - 0s 99us/sample - loss: 0.4027 - accuracy: 0.8260 - val_loss: 0.5393 - val_accuracy: 0.7865\n",
      "Epoch 21/40\n",
      "793/793 [==============================] - 0s 103us/sample - loss: 0.4123 - accuracy: 0.8071 - val_loss: 0.5462 - val_accuracy: 0.7753\n",
      "Epoch 22/40\n",
      "793/793 [==============================] - 0s 96us/sample - loss: 0.4054 - accuracy: 0.8197 - val_loss: 0.5448 - val_accuracy: 0.7865\n",
      "Epoch 23/40\n",
      "793/793 [==============================] - 0s 102us/sample - loss: 0.4039 - accuracy: 0.8197 - val_loss: 0.5441 - val_accuracy: 0.7753\n",
      "Epoch 24/40\n",
      "793/793 [==============================] - 0s 106us/sample - loss: 0.4063 - accuracy: 0.8235 - val_loss: 0.5451 - val_accuracy: 0.7753\n",
      "Epoch 25/40\n",
      "793/793 [==============================] - 0s 97us/sample - loss: 0.4049 - accuracy: 0.8222 - val_loss: 0.5386 - val_accuracy: 0.7978\n",
      "Epoch 26/40\n",
      "793/793 [==============================] - 0s 99us/sample - loss: 0.4001 - accuracy: 0.8247 - val_loss: 0.5465 - val_accuracy: 0.7640\n",
      "Epoch 27/40\n",
      "793/793 [==============================] - 0s 96us/sample - loss: 0.4079 - accuracy: 0.8108 - val_loss: 0.5314 - val_accuracy: 0.7528\n",
      "Epoch 28/40\n",
      "793/793 [==============================] - 0s 93us/sample - loss: 0.4005 - accuracy: 0.8209 - val_loss: 0.5402 - val_accuracy: 0.7865\n",
      "Epoch 29/40\n",
      "793/793 [==============================] - 0s 96us/sample - loss: 0.3979 - accuracy: 0.8235 - val_loss: 0.5374 - val_accuracy: 0.7753\n",
      "Epoch 30/40\n",
      "793/793 [==============================] - 0s 90us/sample - loss: 0.4007 - accuracy: 0.8197 - val_loss: 0.5370 - val_accuracy: 0.7978\n",
      "Epoch 31/40\n",
      "793/793 [==============================] - 0s 92us/sample - loss: 0.4014 - accuracy: 0.8159 - val_loss: 0.5403 - val_accuracy: 0.8090\n",
      "Epoch 32/40\n",
      "793/793 [==============================] - 0s 97us/sample - loss: 0.3980 - accuracy: 0.8348 - val_loss: 0.5379 - val_accuracy: 0.7865\n",
      "Epoch 33/40\n",
      "793/793 [==============================] - 0s 97us/sample - loss: 0.3952 - accuracy: 0.8285 - val_loss: 0.5444 - val_accuracy: 0.7978\n",
      "Epoch 34/40\n",
      "793/793 [==============================] - 0s 100us/sample - loss: 0.3965 - accuracy: 0.8310 - val_loss: 0.5322 - val_accuracy: 0.7640\n",
      "Epoch 35/40\n",
      "793/793 [==============================] - 0s 102us/sample - loss: 0.3931 - accuracy: 0.8235 - val_loss: 0.5404 - val_accuracy: 0.7865\n",
      "Epoch 36/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.3968 - accuracy: 0.8310 - val_loss: 0.5384 - val_accuracy: 0.7753\n",
      "Epoch 37/40\n",
      "793/793 [==============================] - 0s 101us/sample - loss: 0.3917 - accuracy: 0.8323 - val_loss: 0.5357 - val_accuracy: 0.7753\n",
      "Epoch 38/40\n",
      "793/793 [==============================] - 0s 97us/sample - loss: 0.3921 - accuracy: 0.8323 - val_loss: 0.5491 - val_accuracy: 0.7753\n",
      "Epoch 39/40\n",
      "793/793 [==============================] - 0s 105us/sample - loss: 0.3929 - accuracy: 0.8260 - val_loss: 0.5444 - val_accuracy: 0.7978\n",
      "Epoch 40/40\n",
      "793/793 [==============================] - 0s 99us/sample - loss: 0.3909 - accuracy: 0.8361 - val_loss: 0.5380 - val_accuracy: 0.7865\n",
      "Porcentagem de Acerto 52.38%\n",
      "Porcentagem de Acerto 0.0%\n",
      "Train on 793 samples, validate on 89 samples\n",
      "Epoch 1/40\n",
      "793/793 [==============================] - 1s 753us/sample - loss: 0.5973 - accuracy: 0.7680 - val_loss: 0.5697 - val_accuracy: 0.7303\n",
      "Epoch 2/40\n",
      "793/793 [==============================] - 0s 98us/sample - loss: 0.4608 - accuracy: 0.7982 - val_loss: 0.5491 - val_accuracy: 0.7416\n",
      "Epoch 3/40\n",
      "793/793 [==============================] - 0s 103us/sample - loss: 0.4403 - accuracy: 0.8008 - val_loss: 0.5349 - val_accuracy: 0.7528\n",
      "Epoch 4/40\n",
      "793/793 [==============================] - 0s 105us/sample - loss: 0.4303 - accuracy: 0.8045 - val_loss: 0.5408 - val_accuracy: 0.7640\n",
      "Epoch 5/40\n",
      "793/793 [==============================] - 0s 103us/sample - loss: 0.4230 - accuracy: 0.8071 - val_loss: 0.5414 - val_accuracy: 0.7303\n",
      "Epoch 6/40\n",
      "793/793 [==============================] - 0s 101us/sample - loss: 0.4192 - accuracy: 0.8096 - val_loss: 0.5305 - val_accuracy: 0.7753\n",
      "Epoch 7/40\n",
      "793/793 [==============================] - 0s 91us/sample - loss: 0.4171 - accuracy: 0.8071 - val_loss: 0.5388 - val_accuracy: 0.7640\n",
      "Epoch 8/40\n",
      "793/793 [==============================] - 0s 108us/sample - loss: 0.4212 - accuracy: 0.8083 - val_loss: 0.5410 - val_accuracy: 0.7865\n",
      "Epoch 9/40\n",
      "793/793 [==============================] - 0s 97us/sample - loss: 0.4154 - accuracy: 0.8033 - val_loss: 0.5428 - val_accuracy: 0.7753\n",
      "Epoch 10/40\n",
      "793/793 [==============================] - 0s 97us/sample - loss: 0.4146 - accuracy: 0.8071 - val_loss: 0.5379 - val_accuracy: 0.7753\n",
      "Epoch 11/40\n",
      "793/793 [==============================] - 0s 103us/sample - loss: 0.4088 - accuracy: 0.8159 - val_loss: 0.5382 - val_accuracy: 0.7865\n",
      "Epoch 12/40\n",
      "793/793 [==============================] - 0s 102us/sample - loss: 0.4075 - accuracy: 0.8071 - val_loss: 0.5392 - val_accuracy: 0.7978\n",
      "Epoch 13/40\n",
      "793/793 [==============================] - 0s 108us/sample - loss: 0.4092 - accuracy: 0.8209 - val_loss: 0.5516 - val_accuracy: 0.7753\n",
      "Epoch 14/40\n",
      "793/793 [==============================] - 0s 105us/sample - loss: 0.4083 - accuracy: 0.8197 - val_loss: 0.5460 - val_accuracy: 0.7753\n",
      "Epoch 15/40\n",
      "793/793 [==============================] - 0s 96us/sample - loss: 0.4080 - accuracy: 0.8197 - val_loss: 0.5342 - val_accuracy: 0.7865\n",
      "Epoch 16/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "793/793 [==============================] - 0s 104us/sample - loss: 0.4032 - accuracy: 0.8146 - val_loss: 0.5447 - val_accuracy: 0.7416\n",
      "Epoch 17/40\n",
      "793/793 [==============================] - 0s 99us/sample - loss: 0.4053 - accuracy: 0.8172 - val_loss: 0.5355 - val_accuracy: 0.7865\n",
      "Epoch 18/40\n",
      "793/793 [==============================] - 0s 101us/sample - loss: 0.4021 - accuracy: 0.8235 - val_loss: 0.5598 - val_accuracy: 0.7416\n",
      "Epoch 19/40\n",
      "793/793 [==============================] - 0s 104us/sample - loss: 0.4031 - accuracy: 0.8235 - val_loss: 0.5324 - val_accuracy: 0.8090\n",
      "Epoch 20/40\n",
      "793/793 [==============================] - 0s 101us/sample - loss: 0.4014 - accuracy: 0.8272 - val_loss: 0.5423 - val_accuracy: 0.7865\n",
      "Epoch 21/40\n",
      "793/793 [==============================] - 0s 105us/sample - loss: 0.3979 - accuracy: 0.8272 - val_loss: 0.5381 - val_accuracy: 0.7865\n",
      "Epoch 22/40\n",
      "793/793 [==============================] - 0s 104us/sample - loss: 0.3999 - accuracy: 0.8272 - val_loss: 0.5355 - val_accuracy: 0.7978\n",
      "Epoch 23/40\n",
      "793/793 [==============================] - 0s 98us/sample - loss: 0.3966 - accuracy: 0.8222 - val_loss: 0.5379 - val_accuracy: 0.8090\n",
      "Epoch 24/40\n",
      "793/793 [==============================] - 0s 108us/sample - loss: 0.3953 - accuracy: 0.8272 - val_loss: 0.5352 - val_accuracy: 0.8090\n",
      "Epoch 25/40\n",
      "793/793 [==============================] - 0s 96us/sample - loss: 0.3973 - accuracy: 0.8235 - val_loss: 0.5423 - val_accuracy: 0.7865\n",
      "Epoch 26/40\n",
      "793/793 [==============================] - 0s 104us/sample - loss: 0.3967 - accuracy: 0.8411 - val_loss: 0.5525 - val_accuracy: 0.7416\n",
      "Epoch 27/40\n",
      "793/793 [==============================] - 0s 105us/sample - loss: 0.3991 - accuracy: 0.8184 - val_loss: 0.5448 - val_accuracy: 0.7865\n",
      "Epoch 28/40\n",
      "793/793 [==============================] - 0s 102us/sample - loss: 0.3995 - accuracy: 0.8159 - val_loss: 0.5418 - val_accuracy: 0.7865\n",
      "Epoch 29/40\n",
      "793/793 [==============================] - 0s 101us/sample - loss: 0.3940 - accuracy: 0.8285 - val_loss: 0.5407 - val_accuracy: 0.7865\n",
      "Epoch 30/40\n",
      "793/793 [==============================] - 0s 96us/sample - loss: 0.3941 - accuracy: 0.8260 - val_loss: 0.5357 - val_accuracy: 0.7865\n",
      "Epoch 31/40\n",
      "793/793 [==============================] - 0s 96us/sample - loss: 0.3910 - accuracy: 0.8235 - val_loss: 0.5452 - val_accuracy: 0.7865\n",
      "Epoch 32/40\n",
      "793/793 [==============================] - 0s 96us/sample - loss: 0.3899 - accuracy: 0.8285 - val_loss: 0.5379 - val_accuracy: 0.7753\n",
      "Epoch 33/40\n",
      "793/793 [==============================] - 0s 98us/sample - loss: 0.3895 - accuracy: 0.8335 - val_loss: 0.5450 - val_accuracy: 0.7865\n",
      "Epoch 34/40\n",
      "793/793 [==============================] - 0s 98us/sample - loss: 0.3910 - accuracy: 0.8222 - val_loss: 0.5429 - val_accuracy: 0.8090\n",
      "Epoch 35/40\n",
      "793/793 [==============================] - 0s 107us/sample - loss: 0.3900 - accuracy: 0.8235 - val_loss: 0.5423 - val_accuracy: 0.8090\n",
      "Epoch 36/40\n",
      "793/793 [==============================] - 0s 121us/sample - loss: 0.3894 - accuracy: 0.8197 - val_loss: 0.5515 - val_accuracy: 0.7865\n",
      "Epoch 37/40\n",
      "793/793 [==============================] - 0s 114us/sample - loss: 0.3871 - accuracy: 0.8272 - val_loss: 0.5454 - val_accuracy: 0.8090\n",
      "Epoch 38/40\n",
      "793/793 [==============================] - 0s 95us/sample - loss: 0.3861 - accuracy: 0.8260 - val_loss: 0.5427 - val_accuracy: 0.8090\n",
      "Epoch 39/40\n",
      "793/793 [==============================] - 0s 99us/sample - loss: 0.3875 - accuracy: 0.8335 - val_loss: 0.5539 - val_accuracy: 0.7753\n",
      "Epoch 40/40\n",
      "793/793 [==============================] - 0s 105us/sample - loss: 0.3879 - accuracy: 0.8235 - val_loss: 0.5452 - val_accuracy: 0.8090\n",
      "Porcentagem de Acerto 53.51%\n",
      "Porcentagem de Acerto 0.0%\n"
     ]
    }
   ],
   "source": [
    "v ={}\n",
    "for n in range(2,50,2):\n",
    "  model = creat_model(n)\n",
    "  history= treinar(model,40)\n",
    "  v[str(n)] = [predict(X_train,y_train,model),predict(X_test,y_test,model),history,model]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2': [53.63,\n",
       "  0.0,\n",
       "  <tensorflow.python.keras.callbacks.History at 0x7f00300ea5c0>,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x7f0030c71518>],\n",
       " '4': [52.72,\n",
       "  0.0,\n",
       "  <tensorflow.python.keras.callbacks.History at 0x7f002821ae48>,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x7f00301a55f8>],\n",
       " '6': [53.29,\n",
       "  0.0,\n",
       "  <tensorflow.python.keras.callbacks.History at 0x7f00207dc630>,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x7f0028214358>],\n",
       " '8': [53.63,\n",
       "  0.0,\n",
       "  <tensorflow.python.keras.callbacks.History at 0x7f00205d0048>,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x7f00206f4f60>],\n",
       " '10': [53.06,\n",
       "  0.0,\n",
       "  <tensorflow.python.keras.callbacks.History at 0x7f00204e7c50>,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x7f00204e1e48>],\n",
       " '12': [53.51,\n",
       "  0.0,\n",
       "  <tensorflow.python.keras.callbacks.History at 0x7f0020265e80>,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x7f00202ebc50>],\n",
       " '14': [52.95,\n",
       "  0.0,\n",
       "  <tensorflow.python.keras.callbacks.History at 0x7f00200a7898>,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x7f0020322550>],\n",
       " '16': [52.83,\n",
       "  0.0,\n",
       "  <tensorflow.python.keras.callbacks.History at 0x7f00200a7128>,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x7f0000701198>],\n",
       " '18': [53.4,\n",
       "  0.0,\n",
       "  <tensorflow.python.keras.callbacks.History at 0x7f0028209cc0>,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x7f00207c5f28>],\n",
       " '20': [50.91,\n",
       "  0.0,\n",
       "  <tensorflow.python.keras.callbacks.History at 0x7f0000df5e10>,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x7f0000e9ae48>],\n",
       " '22': [51.02,\n",
       "  0.0,\n",
       "  <tensorflow.python.keras.callbacks.History at 0x7f0000c37828>,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x7f0000d397f0>],\n",
       " '24': [53.29,\n",
       "  0.0,\n",
       "  <tensorflow.python.keras.callbacks.History at 0x7f0000a50d68>,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x7f0000ac8cf8>],\n",
       " '26': [52.72,\n",
       "  0.0,\n",
       "  <tensorflow.python.keras.callbacks.History at 0x7f0000850390>,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x7f00009594a8>],\n",
       " '28': [51.59,\n",
       "  0.0,\n",
       "  <tensorflow.python.keras.callbacks.History at 0x7f00005d1470>,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x7f00008c12e8>],\n",
       " '30': [51.25,\n",
       "  0.0,\n",
       "  <tensorflow.python.keras.callbacks.History at 0x7f000046b1d0>,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x7f00004b43c8>],\n",
       " '32': [51.7,\n",
       "  0.0,\n",
       "  <tensorflow.python.keras.callbacks.History at 0x7f0000a87a90>,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x7f0000c5b978>],\n",
       " '34': [52.72,\n",
       "  0.0,\n",
       "  <tensorflow.python.keras.callbacks.History at 0x7f0000313b00>,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x7f000031d978>],\n",
       " '36': [53.17,\n",
       "  0.0,\n",
       "  <tensorflow.python.keras.callbacks.History at 0x7f00000d2278>,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x7f0000156be0>],\n",
       " '38': [50.57,\n",
       "  0.0,\n",
       "  <tensorflow.python.keras.callbacks.History at 0x7effe072efd0>,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x7effe07d8780>],\n",
       " '40': [52.72,\n",
       "  0.0,\n",
       "  <tensorflow.python.keras.callbacks.History at 0x7effe059d828>,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x7effe0594390>],\n",
       " '42': [52.27,\n",
       "  0.0,\n",
       "  <tensorflow.python.keras.callbacks.History at 0x7effe036e0b8>,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x7effe03d9fd0>],\n",
       " '44': [51.13,\n",
       "  0.0,\n",
       "  <tensorflow.python.keras.callbacks.History at 0x7effe0189cf8>,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x7f000018b470>],\n",
       " '46': [52.38,\n",
       "  0.0,\n",
       "  <tensorflow.python.keras.callbacks.History at 0x7effe0049b38>,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x7effe008c9e8>],\n",
       " '48': [53.51,\n",
       "  0.0,\n",
       "  <tensorflow.python.keras.callbacks.History at 0x7effbb750898>,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x7effe00650f0>]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(history):\n",
    "\n",
    "  plt.figure()\n",
    "  plt.plot(history.history['accuracy'],'.r', label = 'acc',alpha = 0.3)\n",
    "  plt.plot(history.history['val_accuracy'], '.b', label = 'acc_val',alpha = 0.3)\n",
    "  plt.legend()\n",
    "  plt.grid()\n",
    "\n",
    "  plt.figure()\n",
    "  plt.plot(history.history['loss'],'.r', label = 'loss',alpha = 0.3)\n",
    "  plt.plot(history.history['val_loss'],'.b', label = 'loss_val',alpha = 0.3)\n",
    "  plt.legend()\n",
    "  plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot(v['80'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Porcentagem de Acerto 80.92%\n",
      "4\n",
      "Porcentagem de Acerto 81.37%\n",
      "6\n",
      "Porcentagem de Acerto 81.03%\n",
      "8\n",
      "Porcentagem de Acerto 82.27%\n",
      "10\n",
      "Porcentagem de Acerto 81.71%\n",
      "12\n",
      "Porcentagem de Acerto 81.93%\n",
      "14\n",
      "Porcentagem de Acerto 82.04%\n",
      "16\n",
      "Porcentagem de Acerto 82.38%\n",
      "18\n",
      "Porcentagem de Acerto 82.49%\n",
      "20\n",
      "Porcentagem de Acerto 82.49%\n",
      "22\n",
      "Porcentagem de Acerto 82.6%\n",
      "24\n",
      "Porcentagem de Acerto 82.83%\n",
      "26\n",
      "Porcentagem de Acerto 82.27%\n",
      "28\n",
      "Porcentagem de Acerto 83.39%\n",
      "30\n",
      "Porcentagem de Acerto 83.5%\n",
      "32\n",
      "Porcentagem de Acerto 82.83%\n",
      "34\n",
      "Porcentagem de Acerto 82.49%\n",
      "36\n",
      "Porcentagem de Acerto 82.6%\n",
      "38\n",
      "Porcentagem de Acerto 82.38%\n",
      "40\n",
      "Porcentagem de Acerto 82.94%\n",
      "42\n",
      "Porcentagem de Acerto 82.72%\n",
      "44\n",
      "Porcentagem de Acerto 82.49%\n",
      "46\n",
      "Porcentagem de Acerto 83.39%\n",
      "48\n",
      "Porcentagem de Acerto 82.49%\n"
     ]
    }
   ],
   "source": [
    "for k in v.keys():\n",
    "    print(k)\n",
    "    predict(X,y_env,v[k][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_test = pd.read_csv('./test.csv')\n",
    "\n",
    "dados_x_test = dados_test.drop(['PassengerId','Name','Ticket','Cabin','Fare','Embarked'],axis =1)\n",
    "\n",
    "\n",
    "#dados_y_test = NÃ£o sabemos... eles nÃ£o disponibilizam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_x_test['Sex'] = dados_x_test['Sex'].apply(sex)\n",
    "\n",
    "\n",
    "dados_x_test = pd.get_dummies(dados_x_test)\n",
    "\n",
    "\n",
    "def media_age(x):\n",
    "    if np.isnan(x) == True :\n",
    "        return int(dados['Age'].mean()+10)\n",
    "        \n",
    "    else:\n",
    "        return x\n",
    "\n",
    "    \n",
    "dados_x_test['Age'] = dados_x_test['Age'].apply(media_age)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_x_test = scaler.fit_transform(dados_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_env = v['22'][3].predict(dados_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_env = pd.DataFrame()\n",
    "dados_env['PassengerId'] = dados_test['PassengerId']\n",
    "dados_env['Survived'] = prev_env[:,0]\n",
    "\n",
    "dados_env['Survived'] = dados_env['Survived'].apply(cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         1\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_env.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7effe072e390>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dados_env.hist('Survived') # EstÃ¡ Coerente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salvar dados\n",
    "\n",
    "dados_env.to_csv('./Attempt_3_Titanic_Predictions.csv',index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
